{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException, ElementNotInteractableException\n",
    "# from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Enter Data to To search form\n",
    "\n",
    "#specify driver path\n",
    "browser = webdriver.Chrome(executable_path= r'C:\\ChromeDriver\\chromedriver.exe')\n",
    "browser.get('https://www.indeed.fr/Paris-(75)-Emplois')\n",
    "# browser.maximize_window()\n",
    "advanced_search = browser.find_element_by_xpath(\"//a[contains(text(),'Recherche avancée')]\")\n",
    "advanced_search.click()\n",
    "\n",
    "\n",
    "#search data science \n",
    "search_job = browser.find_element_by_xpath('//input[@id=\"as_and\"]')\n",
    "search_job.clear()\n",
    "search_job.send_keys(['Data Scientist'])\n",
    "\n",
    "# search Specific skills\n",
    "specific_skills = browser.find_element_by_xpath('//input[@id=\"as_phr\"]')\n",
    "specific_skills.clear()\n",
    "# specific_skills.send_keys(['NLP'])\n",
    "\n",
    "\n",
    "#set display limit of 30 results per page\n",
    "display_limit = browser.find_element_by_xpath('//select[@id=\"limit\"]//option[@value=\"30\"]')\n",
    "display_limit.click()\n",
    "\n",
    "#sort by date\n",
    "sort_option = browser.find_element_by_xpath('//select[@id=\"sort\"]//option[@value=\"date\"]')\n",
    "sort_option.click()\n",
    "\n",
    "# pick alternance\n",
    "# sort_option = browser.find_element_by_xpath('//select[@id=\"jt\"]//option[@value=\"custom_1\"]')\n",
    "# sort_option.click()\n",
    "\n",
    "#  remove cookie banner because it covers the next research button\n",
    "# try:\n",
    "#     cookie_banner = browser.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "#     cookie_banner.click()\n",
    "# except NoSuchElementException:\n",
    "#     pass\n",
    "    \n",
    "search_button = browser.find_element_by_xpath('//*[@id=\"fj\"]')\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# handle pop up \n",
    "# wait about 2 seconds\n",
    "\n",
    "time.sleep(2)\n",
    "try:\n",
    "    close_popup = browser.find_element_by_id(\"popover-x\")\n",
    "    close_popup.click()\n",
    "except (NoSuchElementException,NoSuchWindowException) as e:\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_17ea7986b1f5b00d</td>\n",
       "      <td>DATA ANALYST</td>\n",
       "      <td>Villepinte (93)</td>\n",
       "      <td>INFORMATIS-TS</td>\n",
       "      <td>35 000 € - 55 000 € par an</td>\n",
       "      <td>Dans le cadre d’un important projet avec une e...</td>\n",
       "      <td>https://www.indeed.fr/company/INFORMATIS--TS/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_05c88458c5d9c869</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Courbevoie (92)</td>\n",
       "      <td>IQVIA</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Analyst, Real World &amp; Analytics Solutions...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=05c88458c5d9c8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_b117b0b7559e2118</td>\n",
       "      <td>Stages Data Science</td>\n",
       "      <td>Ivry-sur-Seine (94)</td>\n",
       "      <td>AfterData</td>\n",
       "      <td>None</td>\n",
       "      <td>Stage - Ivry-sur-Seine (Métro)\\nPassionné par ...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=b117b0b7559e21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p_1cd2c87335ba070c</td>\n",
       "      <td>Data scientist-(H/F)</td>\n",
       "      <td>Courbevoie (92)</td>\n",
       "      <td>Société Générale</td>\n",
       "      <td>None</td>\n",
       "      <td>Vos missions au quotidien\\nNous vous proposons...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=1cd2c87335ba07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p_49313c8d820629d9</td>\n",
       "      <td>Data scientist F/H</td>\n",
       "      <td>Courbevoie (92)</td>\n",
       "      <td>autobiz</td>\n",
       "      <td>None</td>\n",
       "      <td>Créée en 2004, autobiz est une start-up innova...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=49313c8d820629...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                 Title             Location  \\\n",
       "0  p_17ea7986b1f5b00d          DATA ANALYST      Villepinte (93)   \n",
       "1  p_05c88458c5d9c869   Senior Data Analyst      Courbevoie (92)   \n",
       "2  p_b117b0b7559e2118   Stages Data Science  Ivry-sur-Seine (94)   \n",
       "3  p_1cd2c87335ba070c  Data scientist-(H/F)      Courbevoie (92)   \n",
       "4  p_49313c8d820629d9    Data scientist F/H      Courbevoie (92)   \n",
       "\n",
       "            Company                      Salary  \\\n",
       "0     INFORMATIS-TS  35 000 € - 55 000 € par an   \n",
       "1             IQVIA                        None   \n",
       "2         AfterData                        None   \n",
       "3  Société Générale                        None   \n",
       "4           autobiz                        None   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Dans le cadre d’un important projet avec une e...   \n",
       "1  Data Analyst, Real World & Analytics Solutions...   \n",
       "2  Stage - Ivry-sur-Seine (Métro)\\nPassionné par ...   \n",
       "3  Vos missions au quotidien\\nNous vous proposons...   \n",
       "4  Créée en 2004, autobiz est une start-up innova...   \n",
       "\n",
       "                                               Links  \n",
       "0  https://www.indeed.fr/company/INFORMATIS--TS/j...  \n",
       "1  https://www.indeed.fr/rc/clk?jk=05c88458c5d9c8...  \n",
       "2  https://www.indeed.fr/rc/clk?jk=b117b0b7559e21...  \n",
       "3  https://www.indeed.fr/rc/clk?jk=1cd2c87335ba07...  \n",
       "4  https://www.indeed.fr/rc/clk?jk=49313c8d820629...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"ID\",\"Title\",\"Location\",\n",
    "                           \"Company\",\"Salary\",\"Description\",\"Links\"])\n",
    "\"\"\"\n",
    "    df_indeed = {'ID': [], 'Title': [], 'Location': [], 'Company': [], 'Links': [], 'Salary': [], 'Descriptions': [],\n",
    "               'Python': [], 'R': [], 'SQL': [], 'NoSQL': [], 'GIT': [], 'Spark': [], 'Flask': [], 'Streamlit': [], 'Docker': [], 'Kubernetes': [],\n",
    "               'React': [], 'VueJS': [], 'AngularJS': [],\n",
    "               'Machine Learning': [], 'Deep Learning': [], 'NLP': [],  'Scala': [], 'PySpark': [],\n",
    "               'PowerBI': [], 'SQLServer': [], 'Dataiku': [], 'Keras': [], 'TensorFlow': [], 'NLU': [],\n",
    "               'PyTorch': [], 'ScikitLearn': [], 'Scikit-Learn': [], 'SAS': [],\n",
    "               'Java': [], 'Scikit learn': [], 'Hadoop': [],  'Hive': [], 'ML DL': [], 'Azure': [], 'AWS': []\n",
    "               }\n",
    " \"\"\"\n",
    "\n",
    "while True :\n",
    "    # Cookies and Popup Handling*\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        if browser.find_element_by_id(\"onetrust-accept-btn-handler\"):\n",
    "            browser.find_element_by_id(\"onetrust-accept-btn-handler\").click()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        if browser.find_element_by_css_selector(\"div.popover-foreground div.popover-x\"):\n",
    "            browser.find_element_by_css_selector(\"div.popover-foreground div.popover-x\").click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    job_card = browser.find_elements_by_css_selector('div.jobsearch-SerpJobCard')\n",
    "\n",
    "    for job in job_card:\n",
    "\n",
    "        # get the id of each job application to filter out the duplicated job offers:\n",
    "        job_id=job.get_attribute('id')\n",
    "\n",
    "        # get the job title \n",
    "        try:\n",
    "            job_title =job.find_element_by_css_selector('h2.title a').get_attribute('title')\n",
    "\n",
    "        except:\n",
    "            job_title = 'None'\n",
    "        # get the job descriptions\n",
    "        try:\n",
    "            job.click()\n",
    "            time.sleep(1)\n",
    "            job_desc=browser.find_element_by_id('vjs-desc').text.strip()\n",
    "            # to close the description window to percept the next button and click o it  \n",
    "            time.sleep(0.25)\n",
    "#                 browser.find_element_by_id('vjs-x').click()\n",
    "\n",
    "        except:\n",
    "            job_desc='None'\n",
    "\n",
    "        # get the job application location \n",
    "        try:\n",
    "            job_location =job.find_element_by_css_selector('div.recJobLoc').get_attribute('data-rc-loc')\n",
    "\n",
    "        except:\n",
    "            job_location='None'\n",
    "\n",
    "        # get the job company name \n",
    "        try:\n",
    "            job_company=job.find_element_by_css_selector('div span.company').text\n",
    "\n",
    "        except:\n",
    "            job_company='None'\n",
    "\n",
    "        # get the salary proposed by the company \n",
    "        try:\n",
    "            job_salary=job.find_element_by_css_selector('span.salaryText').text\n",
    "        except:\n",
    "            job_salary='None'\n",
    "            \n",
    "        # get job links \n",
    "        try:\n",
    "            job_link=job.find_element_by_css_selector(\"h2.title > a\").get_attribute(\"href\")\n",
    "            \n",
    "        except:\n",
    "            job_link='None'\n",
    "            \n",
    "\n",
    "\n",
    "        df = df.append({\"ID\":job_id,'Title':job_title,'Location':job_location,\"Company\":job_company,\"Salary\":job_salary,\n",
    "                        \"Description\":job_desc,'Links':job_link},ignore_index=True)\n",
    "        \n",
    "   \n",
    "        \n",
    "    # scroll down to see the next button \n",
    "    browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "\n",
    "    \n",
    "    # to get the next button because it was interceptable because a tag was hiding it \n",
    "    try:\n",
    "        next_page = browser.find_element_by_xpath(\"//a[@aria-label='Suivant'] | a[contains(text(),'Suivant')] \").get_attribute(name=\"href\")\n",
    "        browser.get(next_page)\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "        print(\"End\")\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Toutes les pages ont été visité\")\n",
    "        break\n",
    "    \n",
    "\n",
    "# store data into csv format\n",
    "df.to_csv('data2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv('dataIndeed.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'ID', 'Title', 'Location', 'Company', 'Salary', 'Description',\n",
       "       'Links'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>p_e1902be83a5c3cee</td>\n",
       "      <td>senior business data analyst</td>\n",
       "      <td>paris (75)</td>\n",
       "      <td>civils de la défense</td>\n",
       "      <td>47 700 € - 50 900 € par an</td>\n",
       "      <td>none</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=e1902be83a5c3c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p_6c20aebcee85ac64</td>\n",
       "      <td>data analyst - h/f</td>\n",
       "      <td>paris 19e (75)</td>\n",
       "      <td>golden bees</td>\n",
       "      <td>38 000 € par an</td>\n",
       "      <td>r / microsoft-excel / sql\\nanalyste data marke...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=6c20aebcee85ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>p_f402d66f9081622f</td>\n",
       "      <td>data analyst - boulogne f/h</td>\n",
       "      <td>boulogne-billancourt (92)</td>\n",
       "      <td>cegedim</td>\n",
       "      <td>none</td>\n",
       "      <td>l'équipe r&amp;d du groupe cegedim évalue et met e...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=f402d66f908162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>p_0c3c13bdb7039f10</td>\n",
       "      <td>data scientist - f/h</td>\n",
       "      <td>la défense (92)</td>\n",
       "      <td>ingeniance</td>\n",
       "      <td>none</td>\n",
       "      <td>contexte:\\nvous assurez la production, la conc...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=0c3c13bdb7039f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>p_8acc248a08d4f035</td>\n",
       "      <td>data analyst (h/f) - boulogne (france)</td>\n",
       "      <td>boulogne-billancourt (92)</td>\n",
       "      <td>cegedim</td>\n",
       "      <td>none</td>\n",
       "      <td>l’équipe r&amp;d du groupe cegedim évalue et met e...</td>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=8acc248a08d4f0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  ID                                   Title  \\\n",
       "0      0  p_e1902be83a5c3cee            senior business data analyst   \n",
       "1      1  p_6c20aebcee85ac64                      data analyst - h/f   \n",
       "2      2  p_f402d66f9081622f             data analyst - boulogne f/h   \n",
       "3      3  p_0c3c13bdb7039f10                    data scientist - f/h   \n",
       "4      4  p_8acc248a08d4f035  data analyst (h/f) - boulogne (france)   \n",
       "\n",
       "                    Location               Company  \\\n",
       "0                 paris (75)  civils de la défense   \n",
       "1             paris 19e (75)           golden bees   \n",
       "2  boulogne-billancourt (92)               cegedim   \n",
       "3            la défense (92)            ingeniance   \n",
       "4  boulogne-billancourt (92)               cegedim   \n",
       "\n",
       "                       Salary  \\\n",
       "0  47 700 € - 50 900 € par an   \n",
       "1             38 000 € par an   \n",
       "2                        none   \n",
       "3                        none   \n",
       "4                        none   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                               none   \n",
       "1  r / microsoft-excel / sql\\nanalyste data marke...   \n",
       "2  l'équipe r&d du groupe cegedim évalue et met e...   \n",
       "3  contexte:\\nvous assurez la production, la conc...   \n",
       "4  l’équipe r&d du groupe cegedim évalue et met e...   \n",
       "\n",
       "                                               Links  \n",
       "0  https://www.indeed.fr/rc/clk?jk=e1902be83a5c3c...  \n",
       "1  https://www.indeed.fr/rc/clk?jk=6c20aebcee85ac...  \n",
       "2  https://www.indeed.fr/rc/clk?jk=f402d66f908162...  \n",
       "3  https://www.indeed.fr/rc/clk?jk=0c3c13bdb7039f...  \n",
       "4  https://www.indeed.fr/rc/clk?jk=8acc248a08d4f0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/32588797/pandas-how-to-apply-a-function-to-different-columns\n",
    "def lower_func(x):\n",
    "    return x.astype(str).str.lower()\n",
    "df[['Title', 'Location', 'Company', 'Salary', 'Description']]=df[['Title', 'Location', 'Company', 'Salary', 'Description']].apply(lower_func,axis=1)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " skills=['python', 'r', 'sql', 'Nosql', 'git', 'spark', 'flask', 'streamlit', 'docker', 'kubernetes',\n",
    "               'react', 'vuejs', 'angularjs',     'machine learning', 'deep learning', 'nlp',  'scala', 'pyspark',\n",
    "               'powerbi', 'sqlserver', 'dataiku', 'keras', 'tensorflow', 'nlu',\n",
    "               'pytorch', 'scikitlearn', 'scikit-learn', 'sas',\n",
    "               'java', 'scikit learn', 'hadoop',  'hive', 'ml dl', 'azure', 'aws']\n",
    "    \n",
    "df['Skills'] = [list() for x in range(len(df.index))]\n",
    "for index, values in df.Description.iteritems():\n",
    "#     print(values.split(' '))\n",
    "#     print('--------------------------------------------------------------------------')\n",
    "    for word in values.split(' '):\n",
    "        if word in skills:\n",
    "            if word not in df['Skills'][index]:\n",
    "#                 print(word, index)\n",
    "                df['Skills'][index].append(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'hadoop', 'sql', 'nlp'] 5\n",
      "['nlp'] 65\n",
      "['nlp', 'java'] 66\n",
      "['nlp'] 68\n",
      "['python', 'nlp'] 77\n",
      "['nlp', 'python', 'tensorflow', 'sql'] 154\n",
      "['nlp', 'python'] 229\n",
      "['nlp', 'python'] 273\n",
      "['python', 'nlp'] 275\n",
      "['hadoop', 'nlp', 'sql'] 341\n",
      "['nlp'] 342\n",
      "['nlp', 'sql', 'r'] 343\n",
      "['hadoop', 'nlp'] 344\n",
      "['nlp', 'pyspark'] 345\n",
      "['nlp'] 347\n",
      "['nlp'] 349\n",
      "['nlp'] 350\n",
      "['nlp'] 351\n",
      "['nlp', 'python'] 392\n"
     ]
    }
   ],
   "source": [
    "for index,i in df['Skills'].iteritems():\n",
    "    if 'nlp' in i :\n",
    "        print(i,index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Skills'] = [skill for skill in skills if df.Description.strip().isin(skills).astype(str)]\n",
    "# df['Skills']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%bash\n",
    "\n",
    "# pip install git+https://github.com/neomatrix369/nlp_profiler.git@master\n",
    "# echo \"Once successfully installed, please restart your Jupyter kernels for the changes to take effect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nlp_profiler.core import apply_text_profiling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Mongo db and Push Data into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1e1769d23c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convertion dataframe en dictionnaire \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_dict.html\n",
    "df.reset_index(inplace=True)\n",
    "data_dict = df.to_dict(\"records\")\n",
    "\n",
    "\n",
    "import pymongo \n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "\n",
    "# # En amont j'ai créer la database jobapplications dans un cmd\n",
    "\n",
    " \n",
    "\n",
    "# Start MongoDB\n",
    "MONGO_HOST= 'mongodb://localhost:27017/'\n",
    "\n",
    " \n",
    "\n",
    "#MongoClient is used to communicate with MongoDB\n",
    "client = MongoClient(MONGO_HOST)\n",
    "\n",
    "\n",
    "\n",
    "#We get a reference to the jobapplications database\n",
    "\n",
    " \n",
    "\n",
    "db=client['job_applications']\n",
    "\n",
    " \n",
    "\n",
    "# create a gene collection and insert jobapplications data \n",
    "db.Indeed.insert_many(data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requete SQL\n",
    "\n",
    "https://api.mongodb.com/python/current/tutorial.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company': 'Civils de la Défense',\n",
      " 'Description': 'None',\n",
      " 'ID': 'p_e1902be83a5c3cee',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=e1902be83a5c3cee&fccid=da943da1ba1f181d&vjs=3',\n",
      " 'Location': 'Paris (75)',\n",
      " 'Salary': '47 700 € - 50 900 € par an',\n",
      " 'Title': 'SENIOR BUSINESS DATA ANALYST',\n",
      " '_id': ObjectId('5f5a138147aa23246ebab4c0'),\n",
      " 'index': 0}\n"
     ]
    }
   ],
   "source": [
    "# printer les \n",
    "import pprint\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "for document in db.Indeed.find():\n",
    "    pp.pprint(document)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "pp.pprint(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monster', 'Indeed']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company': 'Civils de la Défense',\n",
      " 'Description': 'None',\n",
      " 'ID': 'p_e1902be83a5c3cee',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=e1902be83a5c3cee&fccid=da943da1ba1f181d&vjs=3',\n",
      " 'Location': 'Paris (75)',\n",
      " 'Salary': '47 700 € - 50 900 € par an',\n",
      " 'Title': 'SENIOR BUSINESS DATA ANALYST',\n",
      " '_id': ObjectId('5f5a138147aa23246ebab4c0'),\n",
      " 'index': 0}\n"
     ]
    }
   ],
   "source": [
    "# pour afficher une ligne (qu'on appel document)\n",
    "pprint.pprint(db.Indeed.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in db.Indeed.find({\"Description\": \"data\"}):\n",
    "    pprint.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=db.Indeed.aggregate([{ '$match': { 'Company': \"data\" } },{'$limit': 5}])\n",
    "# for i, o in enumerate(result):\n",
    "#     print(i, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { $group: { _id: \"$cust_id\", total: { $sum: \"$amount\" } } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=client['job_applications']\n",
    "mycol = db[\"Indeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company': 'phenix',\n",
      " 'Description': 'data analyst\\n'\n",
      "                '\\n'\n",
      "                'l’entreprise : phenix est la startup leader de la lutte '\n",
      "                'contre le gaspillage en europe, avec plus de 50 millions de '\n",
      "                'repas sauvés depuis son lancement grâce à son réseau de '\n",
      "                'professionnel·les et citoyen·nes engagé·es.\\n'\n",
      "                'localisation : paris 17e - télétravail possible 3 '\n",
      "                'jours/semaine après période d’essai\\n'\n",
      "                'disponibilité : octobre 2020\\n'\n",
      "                'type de contrat : cdi\\n'\n",
      "                'rémunération : compétitive et en fonction du profil + tickets '\n",
      "                'restaurant + 100% abonnement transport en commun\\n'\n",
      "                'site web : www.wearephenix.com\\n'\n",
      "                '\\n'\n",
      "                'rejoignez phenix pour participer à la réduction du gaspillage '\n",
      "                'et à la transition vers une économie circulaire pour ne plus '\n",
      "                'nourrir les poubelles.\\n'\n",
      "                'trois produits techforgood nous permettent de donner une '\n",
      "                'seconde vie aux invendus et de viser le zéro déchet '\n",
      "                'alimentaire :\\n'\n",
      "                'une plateforme saas btob pour digitaliser le don solidaire '\n",
      "                'envers les associations caritatives.\\n'\n",
      "                'une appli mobile grand public permettant aux consommateurs et '\n",
      "                \"consommatrices d'acheter à prix mini les produits en fin de \"\n",
      "                'vie,\\n'\n",
      "                'phenix date, un outil numérique d’aide au contrôle des dates '\n",
      "                'de péremption et à la rotation des produits en rayons\\n'\n",
      "                '\\n'\n",
      "                'au sein de l’équipe data et sous la responsabilité de notre '\n",
      "                'head of data, tu seras au croisement entre la technique et le '\n",
      "                'business. tes analyses et tes tableaux de bord feront de toi '\n",
      "                'la·le partenaire privilégié·e des équipes business et '\n",
      "                'produit.\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'missions\\n'\n",
      "                '\\n'\n",
      "                'modéliser la donnée\\n'\n",
      "                'structurer, modéliser et mettre en forme les données pour les '\n",
      "                'rendre facilement accessible et en tirer de la valeur '\n",
      "                'business.\\n'\n",
      "                'exploiter la donnée\\n'\n",
      "                'définir les kpi à suivre et construire des tableaux de bord '\n",
      "                'automatisés pour piloter les performances et aider les '\n",
      "                'équipes à prendre les bonnes décisions stratégiques au '\n",
      "                'quotidien.\\n'\n",
      "                'collaborer avec nos équipes produit et business pour '\n",
      "                'accroître nos connaissances de l’industrie, de nos client·es '\n",
      "                'et de l’utilisation de nos produits.\\n'\n",
      "                'définir des insights qui auront une valeur pour les métiers, '\n",
      "                'formuler des recommandations sur la base des analyses.\\n'\n",
      "                '\\n'\n",
      "                'evangéliser les équipes phenix sur les sujets data\\n'\n",
      "                'animer des formations internes à l’utilisation de sql et aux '\n",
      "                'outils de data visualisation (looker) afin d’aider les '\n",
      "                'phénicien·ne·s à monter en compétence sur les sujets data et '\n",
      "                'à être de plus en plus autonome dans leur utilisation de la '\n",
      "                'donnée\\n'\n",
      "                'notre stack\\n'\n",
      "                'database: mysql, sql server\\n'\n",
      "                'warehouse: bigquery\\n'\n",
      "                'modelisation/visualization tool: looker\\n'\n",
      "                'crm : salesforce\\n'\n",
      "                'tracking: amplitude\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'profil idéal ?? #moutonacinqpattes\\n'\n",
      "                '\\n'\n",
      "                'tu as 2 ans d’expérience ou plus en tant que data analyst\\n'\n",
      "                'tu excelles en sql, maîtriser python est un +\\n'\n",
      "                'tu as un esprit analytique et une bonne compréhension des '\n",
      "                'enjeux business\\n'\n",
      "                'tu sais comment tirer des informations utiles de grands '\n",
      "                'ensembles de données et tu peux communiquer les conclusions '\n",
      "                'de manière claire et concise. tu es un·e excellent·e '\n",
      "                'pédagogue.\\n'\n",
      "                'tu as une expérience dans la création de dashboard et la data '\n",
      "                'visualisation\\n'\n",
      "                'tu sais prendre des initiatives et faire preuve d’autonomie, '\n",
      "                'tu aimes les challenges et tu n’as pas peur de tout '\n",
      "                'construire de zéro\\n'\n",
      "                'tu veux avoir un impact positif et contribuer au '\n",
      "                'développement d’une ambitieuse start-up de l’économie '\n",
      "                'circulaire\\n'\n",
      "                \"tu parles couramment l'anglais et le français\\n\"\n",
      "                '\\n'\n",
      "                'la data est un domaine qui te passionne et tu souhaites la '\n",
      "                'mettre au service d’une boîte à impact!\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'l’environnement phenix\\n'\n",
      "                '\\n'\n",
      "                'phenix est la startup leader de la lutte contre le gaspillage '\n",
      "                'en europe, avec plus de 100 000 repas sauvés chaque jour '\n",
      "                'grâce à son réseau de professionnel·les et citoyen·nes '\n",
      "                'engagé·es.\\n'\n",
      "                'déterminé·es à bâtir un monde sans gaspillage, les 190 '\n",
      "                'coaches anti-gaspi phenix imaginent et mettent en œuvre des '\n",
      "                'solutions innovantes pour que les invendus (alimentaires et '\n",
      "                'non-alimentaires) ne deviennent jamais des déchets.\\n'\n",
      "                \"dernière-née chez phenix, l'application mobile, qui permet \"\n",
      "                'aux citoyen·nes d’agir concrètement contre le gaspillage en '\n",
      "                'achetant à prix réduit les invendus des commerçants.\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'processus de recrutement\\n'\n",
      "                '\\n'\n",
      "                'envoie-nous ton cv + lm (courte mais personnalisée et motivée '\n",
      "                '- ne pas être trop formel·le, dis-nous vraiment ce qui '\n",
      "                't’intéresse)\\n'\n",
      "                'un entretien téléphonique\\n'\n",
      "                'un test technique à faire chez soi\\n'\n",
      "                'un test technique avec l’équipe data de phenix\\n'\n",
      "                'une rencontre avec les équipes opérationnelles et les rh\\n'\n",
      "                '\\n'\n",
      "                'ce poste est bien sûr ouvert aux personnes en situation de '\n",
      "                'handicap.\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                \"ce que t'offre phenix\\n\"\n",
      "                '\\n'\n",
      "                'de l’autonomie avec un champ d’action très large sur un poste '\n",
      "                'à responsabilités qui est clé pour le développement de '\n",
      "                'l’entreprise\\n'\n",
      "                'travailler au contact d’équipes motivées, dynamiques et '\n",
      "                'engagées\\n'\n",
      "                'un job avec du sens qui permet de réduire le gaspillage '\n",
      "                'alimentaire (3e levier de réduction des gaz à effet de '\n",
      "                'serre)\\n'\n",
      "                'une dimension internationale (france, espagne, portugal)\\n'\n",
      "                '3 jours de télétravail par semaine autorisés',\n",
      " 'ID': 'p_1b1ff56086ef1f30',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=1b1ff56086ef1f30&fccid=c4e859f48e7061da&vjs=3',\n",
      " 'Location': 'paris 17e (75)',\n",
      " 'Salary': '30 000 € - 45 000 € par an',\n",
      " 'Skills': 'pythonsql',\n",
      " 'Title': 'data analyst (h/f)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab849'),\n",
      " 'index': 17,\n",
      " 'level_0': 17}\n",
      "{'Company': 'edf',\n",
      " 'Description': 'type de contrat :\\n'\n",
      "                'cdi\\n'\n",
      "                '\\n'\n",
      "                'niveau de formation :\\n'\n",
      "                'bac +8\\n'\n",
      "                '\\n'\n",
      "                'spécialité(s) :\\n'\n",
      "                'recherche & développement\\n'\n",
      "                '\\n'\n",
      "                'pays / région :\\n'\n",
      "                'france / ile-de-france\\n'\n",
      "                '\\n'\n",
      "                'département :\\n'\n",
      "                'paris (75)\\n'\n",
      "                '\\n'\n",
      "                'ville :\\n'\n",
      "                '9 boulevard gouvion saint cyr\\n'\n",
      "                '\\n'\n",
      "                \"description de l'offre\\n\"\n",
      "                'metroscope, technology that works.\\n'\n",
      "                'metroscope produit un diagnostic en temps réel des '\n",
      "                'industries, reposant sur l’ia. le logiciel améliore le '\n",
      "                'pilotage et la maintenance des usines et centrales '\n",
      "                'électriques pour en améliorer la performance opérationnelle '\n",
      "                'et environnementale. après 2 ans d’existence, elle équipe des '\n",
      "                'centrales nucléaires des 2 côtés de l’atlantique et dispose '\n",
      "                'de bureaux à paris et berlin et d’une présence au us. ses '\n",
      "                'valeurs : simplicité et engagement\\n'\n",
      "                'metroscope est une startup du groupe edf.\\n'\n",
      "                '\\n'\n",
      "                'l’environnement technique\\n'\n",
      "                '\\n'\n",
      "                'codes de data science en python stockés sur github (repos '\n",
      "                'privés)\\n'\n",
      "                'numpy, scipy, pandas, scikit-learn, …\\n'\n",
      "                'chaînes de markov, réseaux bayésiens, machine learning, …\\n'\n",
      "                '\\n'\n",
      "                'ta mission\\n'\n",
      "                '\\n'\n",
      "                'intégré à l’équipe data science, ta mission consistera à :\\n'\n",
      "                'développer les nouvelles technologies de metroscope basées '\n",
      "                'sur des concepts mathématiques probabilistes et le machine '\n",
      "                'learning\\n'\n",
      "                'explorer de nouveaux concepts mathématiques pour étendre le '\n",
      "                'domaine applicatif du logiciel\\n'\n",
      "                'améliorer le cœur de calcul en charge des diagnostics sur '\n",
      "                'lequel repose actuellement notre logiciel\\n'\n",
      "                'contribuer aux expérimentations destinées aux clients qui ont '\n",
      "                'des unités industrielles pour lesquelles notre logiciel n’est '\n",
      "                'pas encore mature\\n'\n",
      "                '\\n'\n",
      "                'pour postuler et en savoir plus sur metroscope : '\n",
      "                'https://www.welcometothejungle.com/fr/companies/metroscope/jobs/data-science_paris\\n'\n",
      "                'profil souhaité\\n'\n",
      "                'ton profil\\n'\n",
      "                'ingénieur avec une formation en mathématiques appliquées et '\n",
      "                'en data science, tu as envie d’utiliser tes compétences pour '\n",
      "                'résoudre de vraies problématiques industrielles, et '\n",
      "                'contribuer à la transition écologique.\\n'\n",
      "                'profondément intéressé par les mathématiques, la data science '\n",
      "                'et l’algorithmie, tu es curieux, autonome et tu t’épanouis '\n",
      "                'dans la résolution de problèmes techniques complexes.\\n'\n",
      "                'tu rejoindras un projet à forts enjeux et une petite équipe '\n",
      "                'solidaire dans laquelle chacun se voit confier de fortes '\n",
      "                'responsabilités. l’esprit d’équipe est de mise tout comme '\n",
      "                'l’autonomie et la prise d’initiative !\\n'\n",
      "                '\\n'\n",
      "                'compétences requises\\n'\n",
      "                'solides compétences en mathématiques : statistiques, '\n",
      "                'probabilités, algorithmie\\n'\n",
      "                'data science : écosystème, frameworks, méthodes. pour ce '\n",
      "                'poste, il conviendra de ne pas être un simple utilisateur des '\n",
      "                'librairies standards de data science : une compréhension fine '\n",
      "                'du fonctionnement des algorithmes classiques sera '\n",
      "                'nécessaire.\\n'\n",
      "                'l’habitude de travailler avec des séries temporelles sera un '\n",
      "                'atout\\n'\n",
      "                'bonne maîtrise de python\\n'\n",
      "                'la connaissance du monde du développement informatique sera '\n",
      "                'un atout\\n'\n",
      "                'anglais courant\\n'\n",
      "                '\\n'\n",
      "                'expérience attendue\\n'\n",
      "                'ingénieur en sortie d’école, doctorant, ou data scientist '\n",
      "                'avec 2-3 ans d’expérience et une forte appétence pour les '\n",
      "                'mathématiques.\\n'\n",
      "                'le contenu du poste pourra être ajusté en fonction de '\n",
      "                'l’expérience du candidat qui sera finalement retenu.\\n'\n",
      "                '\\n'\n",
      "                'pour postuler et en savoir plus sur metroscope : '\n",
      "                'https://www.welcometothejungle.com/fr/companies/metroscope/jobs/data-science_paris',\n",
      " 'ID': 'p_17fe2a565cab665b',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=17fe2a565cab665b&fccid=0103fd28b454bd4a&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'python',\n",
      " 'Title': 'data scientist h/f',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab857'),\n",
      " 'index': 31,\n",
      " 'level_0': 31}\n"
     ]
    }
   ],
   "source": [
    "   myquery = {\n",
    "    \"Company\" : { \"$in\": [\"phenix\", \"edf\"] },\n",
    "    \"Location\" : { \"$regex\": \"paris\" }\n",
    "}\n",
    "    \n",
    "mydoc = mycol.find(myquery)\n",
    "for x in mydoc:\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company': 'scient',\n",
      " 'Description': 'nous cherchons notre data scientist\\n'\n",
      "                'la mission : comprendre le métier et le traduire en '\n",
      "                'spécifications techniques. en étroite collaboration avec une '\n",
      "                'petite équipe vous serez en charge :\\n'\n",
      "                'elaboration de projet et programmation en data-science\\n'\n",
      "                'participer au développement des solutions\\n'\n",
      "                'mise en place des technologies d’ia et de nlp\\n'\n",
      "                '\\n'\n",
      "                'profil recherché les prérequis : vous justifiez '\n",
      "                'impérativement d’une première expérience en python/js, vous '\n",
      "                'êtes diplômé d’un master en informatique ou d’un diplôme '\n",
      "                'd’ingénieur (ingénieur informaticien) et vous maîtrisez au '\n",
      "                'moins deux des compétences suivantes :\\n'\n",
      "                'algo : python (tornado, flask), javascript (nodejs)\\n'\n",
      "                'data : mongodb, arangodb, postgresql, elasticsearch, '\n",
      "                'rabbitmq\\n'\n",
      "                'linux, docker\\n'\n",
      "                'la maîtrise des compétences suivantes serait un plus pour ce '\n",
      "                'poste :\\n'\n",
      "                'algo : go, java, spark, redis, django\\n'\n",
      "                'front : angularjs, reactjs, d3js\\n'\n",
      "                'data-science : machine learning algorithms (svm, '\n",
      "                'randomforest, xgboost, logistic...), connaissance des réseaux '\n",
      "                'de neurones et python / apis (numpy, pandas, scikit learn, '\n",
      "                'keras...)\\n'\n",
      "                'vous souhaitez rejoindre une équipe passionnée '\n",
      "                'd’informatique, d’ia et d’innovations et que vous maîtrisez '\n",
      "                'les compétences nécessaires :\\n'\n",
      "                'alors rencontrons-nous !\\n'\n",
      "                '\\n'\n",
      "                'entreprise chez scient nous sommes des project makers.\\n'\n",
      "                'grâce à une approche innovante et non-conventionnelle centrée '\n",
      "                'sur les usages, les méthodes agiles et notre expertise data, '\n",
      "                'nous transformons les challenges de nos clients en succès.\\n'\n",
      "                'notre team-spirit orienté sur le développement personnel de '\n",
      "                'nos collaborateurs et sur les valeurs du sport nous confère '\n",
      "                'une place toute particulière dans notre écosystème.\\n'\n",
      "                'rejoindre notre aventure, c’est rejoindre une entreprise en '\n",
      "                'forte croissance et pleine d’ambitions avec des projets '\n",
      "                'passionnants dans un cadre idéal à paris et à '\n",
      "                'aix-en-provence.',\n",
      " 'ID': 'p_5925592fb95b65e2',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=5925592fb95b65e2&fccid=dd616958bd9ddc12&vjs=3',\n",
      " 'Location': 'paris 1er (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'python',\n",
      " 'Title': 'data scientist f/h',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab841'),\n",
      " 'index': 9,\n",
      " 'level_0': 9}\n",
      "{'Company': 'sept lieues',\n",
      " 'Description': 'start up/foodtech en croissance, engagée, qui intervient pour '\n",
      "                'le grand public.\\n'\n",
      "                'le poste / les missions\\n'\n",
      "                \"au sein d'une équipe tech de 8 personnes, vous serez \"\n",
      "                'entouré(e) de 3 autres data scientist.\\n'\n",
      "                'vos missions seront les suivantes :\\n'\n",
      "                'développer des algorithmes de prévision\\n'\n",
      "                'scoring de clients\\n'\n",
      "                \"maintien et amélioration de l'existant\\n\"\n",
      "                '\\n'\n",
      "                'vous travaillerez sur de gros volumes de données. vous '\n",
      "                'utiliserez des techniques de nlp, ainsi que de deep '\n",
      "                'learning.\\n'\n",
      "                'profil recherché\\n'\n",
      "                'avoir une première expérience professionnelle\\n'\n",
      "                \"être à l'aise avec les méthodes de nlp\\n\"\n",
      "                'avoir un profil data business et non recherche\\n'\n",
      "                '\\n'\n",
      "                'le plus ? avoir travailler sur des algos de recommandation',\n",
      " 'ID': 'p_91018afba1f113b1',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=91018afba1f113b1&fccid=d98bfa22633409bb&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': '',\n",
      " 'Title': 'data scientist + 3ans',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab843'),\n",
      " 'index': 11,\n",
      " 'level_0': 11}\n",
      "{'Company': 'ysance',\n",
      " 'Description': 'acteur reconnu sur le marché de la data, ysance poursuit sa '\n",
      "                'croissance et son développement en intégrant au sein de ses '\n",
      "                'équipes de nouveaux experts en recrutant des profils senior '\n",
      "                'data scientist.\\n'\n",
      "                'au sein de l’équipe data services et en tant que senior data '\n",
      "                'scientist, vous contribuerez à la réalisation de projets '\n",
      "                'technologiques en data science et intelligence artificielle.\\n'\n",
      "                '✔️ votre mission consistera à répondre à un besoin métier '\n",
      "                'grâce à la data science, de bout en bout : concevoir, '\n",
      "                'développer, tester et industrialiser.\\n'\n",
      "                '✔️ vous serez impliqué(e) dans la mise en place de modèles de '\n",
      "                'machine learning pour développer des cas d’usage clients '\n",
      "                'variés : allant du marketing prédictif (segmentation clients, '\n",
      "                'scoring, recommandation de produits ou détection de fraude) à '\n",
      "                'la reconnaissance d’images (deep learning), en passant par le '\n",
      "                'traitement naturel du langage (nlp),\\n'\n",
      "                '✔️ vous interviendrez, en étroite collaboration avec les data '\n",
      "                'engineers, à l’industrialisation et la mise en production des '\n",
      "                'modèles et des pipelines de transformation de données '\n",
      "                'développés,\\n'\n",
      "                '✔️ vous serez amené.e à accompagner nos clients dans la '\n",
      "                'résolution de leurs problématiques data. a cet égard, vous '\n",
      "                'êtes capable de vulgariser des concepts complexes de data '\n",
      "                'science, d’évangéliser et de partager vos connaissances,\\n'\n",
      "                '✔️ garant de la connaissance métier à travers l’appropriation '\n",
      "                'des enjeux et des problématiques opérationnelles, votre '\n",
      "                'expertise technique vous permettra d’être force de '\n",
      "                'proposition dans la mise en place de nouveaux cas d’usage '\n",
      "                'client.\\n'\n",
      "                '➡️ environnement technique : machine learning, nlp, deep '\n",
      "                'learning, python, r, sql, nosql, hadoop, hive, spark, aws, '\n",
      "                'azure, etc.\\n'\n",
      "                '\\n'\n",
      "                'profil recherché issu(e) d’une formation supérieure, bac+5 '\n",
      "                '(diplômé(e) d’une école d’ingénieurs, titulaire d’un doctorat '\n",
      "                'ou d’un master spécialisé) , avec une expérience '\n",
      "                'professionnelle d’au moins 3 ans en data science.\\n'\n",
      "                'vous connaissez les langages de programmation (python, r, '\n",
      "                'sql, sas, ...) et les bases de données (sql, nosql).\\n'\n",
      "                \"une expérience pratique de l'écosystème big data (hadoop, \"\n",
      "                'hive, …) et de l’utilisation d’outils d’informatique '\n",
      "                'distribuée (spark/pyspark) serait appréciée. en outre, vous '\n",
      "                'avez déjà réalisé un projet (académique ou professionnel) en '\n",
      "                'nlp ou en deep learning.\\n'\n",
      "                \"la connaissance d'une des plateformes cloud (aws, azure, gcp) \"\n",
      "                'serait un plus,\\n'\n",
      "                \"doté(e) d'un très bon relationnel, passionné(e) par la data, \"\n",
      "                \"vous faites preuve d'une capacité d'abstraction et de prise \"\n",
      "                'de recul. vos qualités rédactionnelles, votre orientation '\n",
      "                'client et votre rigueur seront les clés de votre réussite '\n",
      "                'pour ce poste.\\n'\n",
      "                '\\n'\n",
      "                'entreprise ysance est une société spécialisée dans le '\n",
      "                'traitement de la data.\\n'\n",
      "                \"nous couvrons l'ensemble de la chaîne de valeur data :\\n\"\n",
      "                '✔️ intégration de données (talend etl, esb, data quality)\\n'\n",
      "                '✔️ big data (cloudera, hortonworks, snowflake, big query)\\n'\n",
      "                '✔️ cloud (amazon, microsoft, google)\\n'\n",
      "                '✔️ data science, prédictif, prescriptif (r, python, dataiku)\\n'\n",
      "                '✔️ analytics (qlikview, qliksense, tableau software, toucan '\n",
      "                'toco)\\n'\n",
      "                'nous avons également développé des offres autour du '\n",
      "                'référentiel client unique (rcu), du périmètre e-rfm et du '\n",
      "                'customer analytics.\\n'\n",
      "                'dans le cadre de notre développement et de nos projets, nous '\n",
      "                'recherchons de nouveaux talents passionnés comme nous par la '\n",
      "                'data.\\n'\n",
      "                '✔️ notre valeur ajoutée ?\\n'\n",
      "                'une forte expertise technique autour de la data qui repose '\n",
      "                'sur nos équipes et qui est renforcée par de nombreux '\n",
      "                'partenariats avec les éditeurs dans le domaine du big data & '\n",
      "                'analytics.\\n'\n",
      "                '✔️pourquoi nous rejoindre ?\\n'\n",
      "                'une forte culture data, des clients de renoms dans des '\n",
      "                'secteurs variés, une approche orientée autour du besoin '\n",
      "                'client afin de répondre au plus près de leurs enjeux.\\n'\n",
      "                'alors si intégrer une structure data driven à taille humaine '\n",
      "                \"répond à vos attentes professionnelles, c'est avec plaisir \"\n",
      "                'que nous échangerons avec nos consultants opérationnels.\\n'\n",
      "                'a bientôt,',\n",
      " 'ID': 'p_d0a6a6fff8708eba',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=d0a6a6fff8708eba&fccid=ec7d969fad906ade&vjs=3',\n",
      " 'Location': 'paris 2e (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'nlp',\n",
      " 'Title': 'data scientist senior f/h',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab87c'),\n",
      " 'index': 68,\n",
      " 'level_0': 68}\n",
      "{'Company': 'ilyeum',\n",
      " 'Description': 'nous recherchons pour le compte de notre client dans le '\n",
      "                'domaine bancaire, un data-scientist sénior afin de renforcer '\n",
      "                'l’équipe intelligence artificielle et modèles.\\n'\n",
      "                '\\n'\n",
      "                'le data scientist senior devra maîtriser le nlp, les '\n",
      "                'algorithmes de clustering ainsi que les outils cloud (azure), '\n",
      "                'serveur unix, python\\n'\n",
      "                'contexte : l’équipe intelligence artificielle et modèles de '\n",
      "                'la direction innovation et data intelligence du secrétariat '\n",
      "                'général a en charge l’ensemble des projets de modélisation '\n",
      "                'pour les fonctions de contrôle de notre client (juridique, '\n",
      "                'conformité, sécurité, ...)\\n'\n",
      "                '\\n'\n",
      "                'objectifs : l’objectif du data scientist est de travailler '\n",
      "                'sur l’intégralité d’un projet data science :\\n'\n",
      "                'collecte des données\\n'\n",
      "                'construction du pipeline\\n'\n",
      "                'analyse descriptive et constructions de features\\n'\n",
      "                'modélisation, ajustement des paramètres\\n'\n",
      "                'restitution des résultats du modèle',\n",
      " 'ID': 'p_38fb8d498a2215d5',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=38fb8d498a2215d5&fccid=6266a31dafd18ba8&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '550 € par jour',\n",
      " 'Skills': '',\n",
      " 'Title': 'data-scientist sénior nlp/algorithme de clustering /python (h/f) / '\n",
      "          'freelance',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab882'),\n",
      " 'index': 74,\n",
      " 'level_0': 74}\n",
      "{'Company': 'seyos',\n",
      " 'Description': \"description de l'entreprise :\\n\"\n",
      "                'seyos est un cabinet de recrutement spécialisé dans les '\n",
      "                \"métiers de l'it. nous proposons aux candidats des \"\n",
      "                'opportunités professionnelles uniquement au sein de clients '\n",
      "                'finaux : éditeurs de logiciels, startups, dsi.\\n'\n",
      "                '\\n'\n",
      "                'description du poste :\\n'\n",
      "                'notre client est une start-up en forte croissance et '\n",
      "                'constituée de 20 collaborateurs qui disrupte le marché de la '\n",
      "                'publicité en ligne en étant la première solution de ciblage '\n",
      "                'publicitaire 100% cookieless.\\n'\n",
      "                '\\n'\n",
      "                \"cette société permet aux annonceurs d'optimiser la diffusion \"\n",
      "                'de leurs publicités non plus en utilisant les données '\n",
      "                \"d'utilisateurs mais en se basant sur les contextes où cette \"\n",
      "                \"population est la plus susceptible d'y être attentive.\\n\"\n",
      "                '\\n'\n",
      "                'basé sur des algorithmes de natural language processing (nlp) '\n",
      "                'et natural language understanding (nlu) appliqués à la '\n",
      "                'publicité programmatique, cette start-up analyse le sens '\n",
      "                'exact des contenus éditoriaux et les sentiments associés pour '\n",
      "                'un ciblage sémantique le plus fin et précis possible.\\n'\n",
      "                '\\n'\n",
      "                \"rejoindre la r&d composée d'une dizaine de collaborateurs, \"\n",
      "                \"c'est travailler dans un univers dynamique, bienveillant et \"\n",
      "                'en pleine expansion.\\n'\n",
      "                '\\n'\n",
      "                'localisation : paris (75002)\\n'\n",
      "                'rémunération : 70 000 / 80 000 euros (annuel)\\n'\n",
      "                '\\n'\n",
      "                'en étroite collaboration avec le cto, vous devrez apporter '\n",
      "                'votre vision de la data et faire progresser les algorithmes '\n",
      "                'sur le long terme.\\n'\n",
      "                '\\n'\n",
      "                'vous serez garant de :\\n'\n",
      "                \"l'intégration de la data dans le dmp pour une utilisation \"\n",
      "                'optimale\\n'\n",
      "                \"faire progresser la technologie en s'appuyant sur de la data\\n\"\n",
      "                'interagir avec les équipes produit, technique et commerciale '\n",
      "                'pour établir une vision long terme de la data\\n'\n",
      "                'créer et gérer une équipe de data scientist de talent\\n'\n",
      "                'travailler en étroite collaboration avec des centres de '\n",
      "                'recherches externes\\n'\n",
      "                \"d'évangéliser, en interne ou en externe, les bonnes pratiques \"\n",
      "                'autour de la data\\n'\n",
      "                'description du profil :\\n'\n",
      "                'votre profil :\\n'\n",
      "                \"vous justifiez d'une première expérience (4 ans minimum) sur \"\n",
      "                'un poste similaire,\\n'\n",
      "                \"vous bénéficiez d'une formation informatique (bac+3 à 5),\\n\"\n",
      "                'vous maitrisez les algorithmes de machine learning,\\n'\n",
      "                \"vous disposez d'une expérience significative sur python et \"\n",
      "                \"l'analyse de sentiment,\\n\"\n",
      "                'vous maitrisez le nlp et vous souhaitez approfondir vos '\n",
      "                'connaissances en traitement de données non structurées,\\n'\n",
      "                \"vous êtes intéressé(e) par d'autres technos (spark, sql, ...) \"\n",
      "                'et pouvez vous adapter à un contexte technologique qui '\n",
      "                'évolue,\\n'\n",
      "                'vous êtes une personne avec un tempérament de leader, '\n",
      "                'impliquée, pragmatique, rigoureuse et autonome.\\n'\n",
      "                'les avantages :\\n'\n",
      "                'télétravail possible (1 jour / semaine)\\n'\n",
      "                'bonne ambiance de travail avec un management jeune et une '\n",
      "                'grande proximité, tout le monde à son mot à dire\\n'\n",
      "                'si ce poste vous intéresse, postulez à cette annonce ou '\n",
      "                'contactez maximilien waeters pour toute question.',\n",
      " 'ID': 'p_9356cc9f9684840b',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=9356cc9f9684840b&fccid=7f56a18d7469ee04&vjs=3',\n",
      " 'Location': 'paris 2e (75)',\n",
      " 'Salary': '70 000 € par an',\n",
      " 'Skills': 'pythonnlp',\n",
      " 'Title': 'lead data science - h/f',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab885'),\n",
      " 'index': 77,\n",
      " 'level_0': 77}\n",
      "{'Company': 'carenity',\n",
      " 'Description': 'fondé en 2011 et disposant d’un bureau à paris et à boston, '\n",
      "                'carenity est le 1er réseau social dédié aux patients et à '\n",
      "                'leurs proches avec plus de 500 000 membres actifs à travers '\n",
      "                'le monde.\\n'\n",
      "                'les missions qui nous animent au quotidien consistent à aider '\n",
      "                'les patients à partager leurs expériences avec des personnes '\n",
      "                'qui leur ressemblent, à les accompagner dans la gestion de '\n",
      "                'leurs maladies et à leur permettre de contribuer aux avancées '\n",
      "                'médicales en participant à des études en ligne.\\n'\n",
      "                'dans le cadre de son fort développement international (eu5, '\n",
      "                'us et canada notamment), carenity recrute plusieurs :\\n'\n",
      "                'pharmaciens – data analysts juniors (cdi / temps plein), à '\n",
      "                'pourvoir dès que possible.\\n'\n",
      "                'au sein de l’équipe data science, vous participerez '\n",
      "                'pleinement à la conduite d’études patients en vie réelle pour '\n",
      "                'nos clients : laboratoires pharmaceutiques, entreprises de '\n",
      "                'technologie médicale, de biotechnologies, fabricants de '\n",
      "                'dispositifs médicaux, services de r&d...\\n'\n",
      "                'vos missions principales – sous la supervision de chefs de '\n",
      "                'projets – data analysts / scientists seniors aux profils '\n",
      "                'variés (pharmaciens, statisticiens, ingénieurs et '\n",
      "                'commerciaux) :\\n'\n",
      "                'participer à la conduite d’études patients en vie réelle '\n",
      "                '(quantitatives et qualitatives) : recherches '\n",
      "                'bibliographiques, rédaction de protocole et de questionnaire, '\n",
      "                'démarches règlementaires, collecte et analyse approfondie des '\n",
      "                'données, rédaction du rapport d’étude et présentation des '\n",
      "                'résultats au client.\\n'\n",
      "                'monter en compétence sur des méthodes d’analyse de données de '\n",
      "                'santé : dce (discrete choices experiment), définition de '\n",
      "                'modèles statistiques, études de préférences patients…\\n'\n",
      "                'faciliter la gestion de la relation client : aider le chef de '\n",
      "                'projet à assurer la gestion de la relation client, '\n",
      "                'participation à l’animation de comités scientifiques...\\n'\n",
      "                'intervenir dans le cadre du développement de nouvelles '\n",
      "                'solutions client : intelligence artificielle, traitement '\n",
      "                'automatique du langage naturel (nlp), identification de '\n",
      "                'nouveaux partenaires scientifiques et technologiques...\\n'\n",
      "                'contribuer à la rédaction et à la publication de posters et '\n",
      "                'd’articles scientifiques dans des journaux de référence ou '\n",
      "                'dans des congrès médicaux\\n'\n",
      "                'utiliser vos connaissances scientifiques et médicales dans le '\n",
      "                'cadre de recherches bibliographiques et pour de la '\n",
      "                'vulgarisation scientifique auprès des collaborateurs non '\n",
      "                'pharmaciens\\n'\n",
      "                'notre organisation étant flexible, ces missions sont non '\n",
      "                'exhaustives et adaptables en fonction du profil et des '\n",
      "                'souhaits d’évolution du candidat : chez carenity, le parcours '\n",
      "                'de chaque collaborateur est personnalisé !\\n'\n",
      "                'profil recherché :\\n'\n",
      "                'les prérequis :\\n'\n",
      "                'profil pharmacien industriel avec un double cursus avec une '\n",
      "                'école d’ingénieur ou de commerce\\n'\n",
      "                'excellentes capacités d’analyse, de rédaction et de synthèse\\n'\n",
      "                'autonomie, proactivité et sens de l’organisationanglais '\n",
      "                'courant (écrit et oral)\\n'\n",
      "                'volonté de s’impliquer dans une jeune entreprise ambitieuse '\n",
      "                'en forte croissance\\n'\n",
      "                'the extra mile ;-) :\\n'\n",
      "                'une première expérience réussie en tant que data analyst / '\n",
      "                'data scientist\\n'\n",
      "                'maîtrise d’un ou plusieurs des logiciels suivants : r, excel '\n",
      "                '(et vba), stata, sas\\n'\n",
      "                'maîtrise d’un ou plusieurs outils de data visualisation\\n'\n",
      "                'aimer les afterworks !\\n'\n",
      "                'poste à temps plein à pourvoir dès que possible\\n'\n",
      "                'société basée à paris 8ème (saint-lazare)\\n'\n",
      "                'package attractif, selon profil\\n'\n",
      "                'vous recherchez une première ou une deuxième expérience '\n",
      "                'exigeante dans laquelle vous pourrez avoir un impact réel '\n",
      "                'dans un environnement stimulant et propice à la prise '\n",
      "                'd’initiative et au développement personnel ?\\n'\n",
      "                'merci d’adresser votre cv et une lettre de motivation par '\n",
      "                'e-mail à : job@carenity.com',\n",
      " 'ID': 'p_de100fa4bd0ff4bd',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=de100fa4bd0ff4bd&fccid=1b6d26905c6064b6&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': '',\n",
      " 'Title': 'business / data analyst santé junior',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab89c'),\n",
      " 'index': 100,\n",
      " 'level_0': 100}\n",
      "{'Company': 'cybelangel',\n",
      " 'Description': 'nous traitons des milliards de documents chaque jour pour en '\n",
      "                'extraire simplement les fuites de données pertinentes '\n",
      "                'concernant nos clients !\\n'\n",
      "                'introduire de l’intelligence aux divers niveaux de notre '\n",
      "                'pipeline de traitement est donc un enjeu crucial pour '\n",
      "                'cybelangel. notre équipe data science a pour mission de '\n",
      "                'rendre nos algorithmes de filtrage les plus intelligents '\n",
      "                'possible, en vue d’optimiser et de faciliter le traitement '\n",
      "                'des incidents de sécurité délivrés à nos clients.\\n'\n",
      "                '\\n'\n",
      "                '**missions**\\n'\n",
      "                'l’équipe data science conçoit, implémente, intègre et '\n",
      "                'optimise des modèles de machine learning pour automatiser '\n",
      "                'intelligemment le traitement massif de documents.\\n'\n",
      "                'au sein de l’équipe, tes missions seront les suivantes:\\n'\n",
      "                \"récupération des data, exploration, état de l'art, \"\n",
      "                'documentation, benchmarking, développement, déploiement. pour '\n",
      "                'quoi faire ? catégoriser, scorer, extraire des informations '\n",
      "                'sensibles (textes et images) !\\n'\n",
      "                'développer et optimiser les algorithmes avec le reste de '\n",
      "                'l’équipe engineering (software developers, full stack '\n",
      "                'developers, devops etc…) pour pouvoir analyser en temps réel '\n",
      "                'des milliards de documents par jour !\\n'\n",
      "                'collaborer avec nos cyber-risk analysts et product managers '\n",
      "                'pour définir et maintenir des objectifs de précision et '\n",
      "                'performance des modèles\\n'\n",
      "                'tester les modèles en environnement de production et mesurer '\n",
      "                'les performances réelles\\n'\n",
      "                'les + du job:\\n'\n",
      "                'faire partie d’une équipe soudée et passionnée de data '\n",
      "                'scientists et data engineers (organisation de cybelkaggle, '\n",
      "                'participation à des conférences, meetup et formations).\\n'\n",
      "                'tu es quotidiennement en lien direct avec les experts '\n",
      "                \"analystes en cybersécurité ce qui te permet d'avoir un impact \"\n",
      "                'global et stratégique.\\n'\n",
      "                'profiter de tous les avantages d’un environnement de travail '\n",
      "                'fun et agréable au quotidien: cours de yoga, petit-déjeuners, '\n",
      "                \"bootcamp, afterworks, meetups et bien d'autres !\\n\"\n",
      "                'possibilité de télétravail à 100%\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'stack techno\\n'\n",
      "                'dbs: elasticsearch, mongo, redis, bigquery\\n'\n",
      "                'infra: gcp, docker, kubernetes, datadog, gitlab ci, rabbitmq\\n'\n",
      "                'frontend: vuejs/vuex, scss, bulma\\n'\n",
      "                'backend: python\\n'\n",
      "                'requirements\\n'\n",
      "                'compétences requises\\n'\n",
      "                '1 à 5 ans d’expérience en tant que data scientist au sein '\n",
      "                \"d'un environnement ml\\n\"\n",
      "                'appétence pour le machine learning\\n'\n",
      "                \"tu est doté d'un esprit d'équipe\\n\"\n",
      "                'bac +5 ou plus en statistique, probabilité, mathématique ou '\n",
      "                'machine learning\\n'\n",
      "                \"expérience minimum d'un an avec python\\n\"\n",
      "                'excellente communication pour pouvoir comprendre, synthétiser '\n",
      "                'et expliquer des problèmes complexes de manière simple avec '\n",
      "                'les équipes product, engineering et analyst.\\n'\n",
      "                'autonomie sur la conception et l’implémentation de nouvelles '\n",
      "                'solutions, force de proposition et créativité\\n'\n",
      "                'compétences appréciées\\n'\n",
      "                'compétence en data/software engineering\\n'\n",
      "                'bon niveau de compréhension en nlp\\n'\n",
      "                'a l’aise en data viz’\\n'\n",
      "                'traitement de datasets volumineux\\n'\n",
      "                'expérience avec des technologies big data : elasticsearch, '\n",
      "                'cassandra, mongodb, hadoop, rabbitmq\\n'\n",
      "                'expérience avec tensorflow/pytorch\\n'\n",
      "                'expérience dans un environnement agile\\n'\n",
      "                'benefits\\n'\n",
      "                'localisation: paris - possibilité de télétravail\\n'\n",
      "                'contrat: cdi à temps plein\\n'\n",
      "                'rémunération: selon profil et expérience',\n",
      " 'ID': 'p_59f34af9d7017d0d',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=59f34af9d7017d0d&fccid=31a8882d159403e5&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': '',\n",
      " 'Title': 'data scientist h/f',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab8a2'),\n",
      " 'index': 106,\n",
      " 'level_0': 106}\n",
      "{'Company': 'wealzy',\n",
      " 'Description': 'votre mission\\n'\n",
      "                'vous participerez à des projets ambitieux de programmation et '\n",
      "                'data science de nos solutions,\\n'\n",
      "                'vous participerez au développement des technologies internes '\n",
      "                'd’ia et d’nlp.\\n'\n",
      "                'en tant que développeur machine learning, vous concevez, '\n",
      "                'assemblez, mettez en place et faites évoluer les algorithmes '\n",
      "                'les plus pertinents permettant de répondre aux problématiques '\n",
      "                'métiers d’investissement immobilier.\\n'\n",
      "                'les approches d’ia sur lesquelles vous travaillez se basent à '\n",
      "                'la fois sur nos données propriétaires, et sur des données '\n",
      "                'externes disponibles ou qui peuvent être collectées par des '\n",
      "                'nouveaux dispositifs à concevoir.\\n'\n",
      "                'vous interagissez au quotidien avec les autres membres de '\n",
      "                'l’équipe de développement, afin de vous assurer que les '\n",
      "                'algorithmes et fonctionnalités mises en place répondent bien '\n",
      "                'aux besoins actuels ou futurs de nos équipes.\\n'\n",
      "                'constamment à la recherche d’approches innovantes pour '\n",
      "                'améliorer la performance de nos plateformes, vous êtes force '\n",
      "                'de proposition sur notre roadmap de développement.\\n'\n",
      "                'les problématiques types sur lesquelles vous pourrez '\n",
      "                'travaillerez sont le développement d’algorithmes prédictifs '\n",
      "                'd’évaluation des prix à la vente et à la location des biens '\n",
      "                'immobiliers\\n'\n",
      "                'notre ambition est de vous offrir un environnement de travail '\n",
      "                'particulièrement stimulant, sur les technologies de pointe en '\n",
      "                'intelligence artificielle et avec une utilisation et un '\n",
      "                'impact direct dans les processus opérationnels de nos clients '\n",
      "                'investisseurs immobiliers.\\n'\n",
      "                '\\n'\n",
      "                'profil recherché bac + 5 en école d’ingénieur\\n'\n",
      "                'python\\n'\n",
      "                'mongodb\\n'\n",
      "                'infra : docker, aws ou google cloud platform\\n'\n",
      "                'data-science: machine learning algorithms (svm, randomforest, '\n",
      "                'xgboost, logistic…), knowledge of the principle of neural '\n",
      "                'networks, knowledge of python packages and apis (numpy, '\n",
      "                'pandas, scikit learn, …)\\n'\n",
      "                '\\n'\n",
      "                'entreprise wealzy propose à ses clients des investissements '\n",
      "                'immobiliers clés en main les plus rentables du marché.\\n'\n",
      "                'les biens sont identifiés et qualifiés grâce à notre solution '\n",
      "                'd’intelligence artificielle permettant d’analyser tout le '\n",
      "                'marché immobilier.\\n'\n",
      "                'wealzy accompagne ses clients sur toutes les phases du projet '\n",
      "                'd’investissement : recherche du bien, recherche de '\n",
      "                'financement, suivi des travaux et mise en location.\\n'\n",
      "                'wealzy développe maintenant une offre digitale à destination '\n",
      "                \"des particuliers et des professionnels de l'immobilier.\\n\"\n",
      "                'nous sommes une startup incubée chez ionis 361 à paris.',\n",
      " 'ID': 'p_8cd494a1b5e044a0',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=8cd494a1b5e044a0&fccid=655a571fd9a73735&vjs=3',\n",
      " 'Location': 'paris 11e (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'pythonaws',\n",
      " 'Title': 'data scientist f/h',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab8a5'),\n",
      " 'index': 109,\n",
      " 'level_0': 109}\n",
      "{'Company': 'sept lieues',\n",
      " 'Description': 'entreprise à taille humaine, dans le secteur financier, dont '\n",
      "                \"la mission est d'aider les startup / pme à se développer. \"\n",
      "                'cette fintech vient de rejoindre un grand groupe et est '\n",
      "                'amenée à collaborer avec des antennes en europe.\\n'\n",
      "                'le poste / les missions\\n'\n",
      "                'en travaillant avec le chief data et dev, vous rejoindrez '\n",
      "                \"l'équipe data composée de deux data scientist et d'un data \"\n",
      "                'engineer.\\n'\n",
      "                '\\n'\n",
      "                'vos missions seront les suivantes :\\n'\n",
      "                '\\n'\n",
      "                'concevoir des modèles de machine learning et nlp\\n'\n",
      "                \"réaliser des outils d'analyse et de b.i\\n\"\n",
      "                'définir le roadmap data\\n'\n",
      "                \"encadrement d'équipe\\n\"\n",
      "                'etre force de proposition sur les nouveaux projets à mener\\n'\n",
      "                '\\n'\n",
      "                'profil recherché\\n'\n",
      "                \"issu(e) d'une école d'ingénieur ou équivalent, vous justifiez \"\n",
      "                \"d'une expérience de minimum 4 ans sur un poste similaire.\\n\"\n",
      "                'vous disposez de capacité analytique et de compétences en '\n",
      "                'machine learning et b.i.\\n'\n",
      "                'vous maîtrisez python et r\\n'\n",
      "                '\\n'\n",
      "                'le plus ? des connaissances en finance',\n",
      " 'ID': 'p_dae2fc6fac3dc90c',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=dae2fc6fac3dc90c&fccid=d98bfa22633409bb&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'python',\n",
      " 'Title': 'lead data scientist',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab8b0'),\n",
      " 'index': 120,\n",
      " 'level_0': 120}\n",
      "{'Company': 'sept lieues',\n",
      " 'Description': 'en travaillant avec le chief data et dev, vous rejoindrez '\n",
      "                \"l'équipe data composée de deux data scientist et d'un data \"\n",
      "                'engineer.\\n'\n",
      "                '\\n'\n",
      "                'vos missions seront les suivantes :\\n'\n",
      "                '\\n'\n",
      "                'concevoir des modèles de machine learning et nlp\\n'\n",
      "                \"réaliser des outils d'analyse et de b.i\\n\"\n",
      "                'définir le roadmap data\\n'\n",
      "                \"encadrement d'équipe\\n\"\n",
      "                'etre force de proposition sur les nouveaux projets à mener\\n'\n",
      "                '\\n'\n",
      "                \"profil recherché issu(e) d'une école d'ingénieur ou \"\n",
      "                \"équivalent, vous justifiez d'une expérience de minimum 4 ans \"\n",
      "                'sur un poste similaire.\\n'\n",
      "                'vous disposez de capacité analytique et de compétences en '\n",
      "                'machine learning et b.i.\\n'\n",
      "                'vous maîtrisez python et r\\n'\n",
      "                '\\n'\n",
      "                'le plus ? des connaissances en finance\\n'\n",
      "                '\\n'\n",
      "                'entreprise entreprise à taille humaine, dans le secteur '\n",
      "                \"financier, dont la mission est d'aider les startup / pme à se \"\n",
      "                'développer. cette fintech vient de rejoindre un grand groupe '\n",
      "                'et est amenée à collaborer avec des antennes en europe.',\n",
      " 'ID': 'p_aa0fd318d1c7ca57',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=aa0fd318d1c7ca57&fccid=d98bfa22633409bb&vjs=3',\n",
      " 'Location': 'paris 1er (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'python',\n",
      " 'Title': 'lead data scientist f/h',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab8be'),\n",
      " 'index': 134,\n",
      " 'level_0': 134}\n",
      "{'Company': 'bluenove',\n",
      " 'Description': 'si la perspective d’améliorer les dispositifs d’intelligence '\n",
      "                'collective , la démocratie d’entreprise et la civic tech via '\n",
      "                'le pouvoir des données t’intéresse : nous avons une mission '\n",
      "                'pour toi.\\n'\n",
      "                'en tant que data scientist au sein de la blueteam, tu auras '\n",
      "                'l’occasion de gérer plusieurs missions pour valoriser les '\n",
      "                'données issues de nos projets. nous sommes à la recherche de '\n",
      "                'notre artiste de la data pour :\\n'\n",
      "                'organiser de la collecte des données issues des '\n",
      "                'concertations\\n'\n",
      "                'préparer et consolider les jeux de données pour nos projets '\n",
      "                'de r&d et nos missions clients\\n'\n",
      "                'modéliser les données issues des débats et donner du sens à '\n",
      "                'leur corrélation\\n'\n",
      "                'interpréter les datasets dans le cadre des projets, notamment '\n",
      "                'par la mise en place d’outils de visualization (#dataviz)\\n'\n",
      "                'assurer une veille technologique sur les aspects '\n",
      "                'mathématiques de la data science (nouvelles méthodes, '\n",
      "                'nouveaux algorithmes, etc.), ainsi que sur les technologies '\n",
      "                '(programmation, big data)\\n'\n",
      "                'tu seras intégré à l’équipe tech, tu collaboreras avec nos '\n",
      "                'chercheurs, l’équipe produit et l’équipe travaillant sur les '\n",
      "                'méthodes assembl.\\n'\n",
      "                'profil recherché\\n'\n",
      "                'nous recherchons un candidat ayant au minimum de 2 ans '\n",
      "                'd’expérience sur une fonction type data scientist (stage et '\n",
      "                'alternance compris), ainsi qu’une forte appétence pour les '\n",
      "                'problématiques d’intelligence collective et sensibilisé aux '\n",
      "                'civic techs.\\n'\n",
      "                'tu es fan de la résolution de problèmes, adepte de la pensée '\n",
      "                'critique, tu fais preuve de créativité, sens de '\n",
      "                'l’organisation, design et compétences interpersonnelles.\\n'\n",
      "                'idéalement, tu as suivi un cursus de type bac+4/5 de grande '\n",
      "                'école en statistiques, mathématiques, informatique, économie, '\n",
      "                'biostatistiques ou autre formation impliquant l’analyse '\n",
      "                'quantitative.\\n'\n",
      "                'les qualités recherchées ?\\n'\n",
      "                'expertise dans diverses facettes de l’apprentissage '\n",
      "                'automatique #machine learning et du traitement du langage '\n",
      "                'naturel #nlp, comme la classification, l’ingénierie des '\n",
      "                'caractéristiques, l’extraction de l’information, la '\n",
      "                'prédiction structurée, le regroupement, l’apprentissage '\n",
      "                'semi-supervisé, la modélisation des sujets et le classement.\\n'\n",
      "                'expérience en machine learning ( régression linéaire, '\n",
      "                'algorithmes non supervisés, deep learning)\\n'\n",
      "                'excellent niveau en statistiques et analyse quantitative '\n",
      "                '(statistiques descriptives, analyses en composantes '\n",
      "                'principales, modèle bayesien)\\n'\n",
      "                'maîtrise de la programmation en r et des bases solides dans '\n",
      "                'des langages de script (python, bash) avec une bonne '\n",
      "                'connaissance des environnements unix/linux.\\n'\n",
      "                'expérience en structure des données: sql, hadoop / nosql , '\n",
      "                'mapreduce, spark, strom\\n'\n",
      "                'maîtrise de l’anglais\\n'\n",
      "                'déroulement des entretiens\\n'\n",
      "                'quand sera traitée ta candidature ?\\n'\n",
      "                'nous traitons les candidatures de data scientist au fil de '\n",
      "                'l’eau, tu auras donc de nos nouvelles la semaine qui suit ta '\n",
      "                'candidature.\\n'\n",
      "                'si ton profil est retenu, nous te proposerons une première '\n",
      "                'rencontre dans nos locaux ou via skype/hangout.\\n'\n",
      "                'quelles sont les différentes étapes de recrutement ?\\n'\n",
      "                'tu auras l’occasion de rencontrer 6 bluenoviens au cours de 3 '\n",
      "                'entretiens (oui tu ne te trompes pas, cela équivaut à 2 '\n",
      "                'personnes par entretien) :\\n'\n",
      "                '#step1 : une rencontre “méthode” avec 1 représentant de '\n",
      "                'l’équipe r&d et 1 consultant, complété d’un cas pratique\\n'\n",
      "                '#step2 : une rencontre “algo & nlp” avec 1 représentant de '\n",
      "                'l’équipe produit & 1 consultant sénior\\n'\n",
      "                '#step3 : une rencontre “carrière” avec 2 managers et/ou '\n",
      "                'partners',\n",
      " 'ID': 'p_a0575907a1c38cbe',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=a0575907a1c38cbe&fccid=17c55221d4055c55&vjs=3',\n",
      " 'Location': 'paris 17e (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'rnosql',\n",
      " 'Title': 'data scientist en concertation',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab8cf'),\n",
      " 'index': 151,\n",
      " 'level_0': 151}\n",
      "{'Company': 'testapic',\n",
      " 'Description': 'testapic est une start-up française spécialisée dans les '\n",
      "                'tests utilisateurs à distance.\\n'\n",
      "                'le principe est simple : solliciter notre panel de testeurs '\n",
      "                'pour qu’ils réalisent depuis chez eux ou en situation de '\n",
      "                'mobilité des tests sur les sites et applis de nos clients. au '\n",
      "                'cours de leur navigation, nos testeurs vont formuler des '\n",
      "                'remarques qui serviront à améliorer l’expérience utilisateur '\n",
      "                '(ux pour les intimes) et donc la performance des interfaces '\n",
      "                'testées.\\n'\n",
      "                'dans une démarche d’innovation, le pôle r&d de testapic '\n",
      "                's’intéresse à de nouvelles problématiques autour de la data '\n",
      "                'et de l’intelligence artificielle avec pour objectif de '\n",
      "                'faciliter le travail de nos experts ux et de nos clients saas '\n",
      "                'en automatisant certaines étapes du processus d’analyse des '\n",
      "                'tests utilisateurs.\\n'\n",
      "                'un certain nombre de briques algorithmiques basées sur le '\n",
      "                'traitement du langage naturel (nlp) ont été développées et '\n",
      "                'sont en cours d’intégration dans notre plateforme de tests. '\n",
      "                'ces algorithmes permettent d’analyser automatiquement le '\n",
      "                'contenu des réponses textuelles issues des questionnaires, '\n",
      "                'd’extraire les informations les plus pertinentes dans les '\n",
      "                'tests de type vidéo (où les testeurs verbalisent à voix haute '\n",
      "                'leur parcours sur les interfaces testées) et d’agréger les '\n",
      "                'opinions concordantes à l’échelle d’une tâche ou d’un '\n",
      "                'ensemble de questions soumises à ces testeurs.\\n'\n",
      "                'le pôle r&d souhaite poursuivre dans cette démarche et '\n",
      "                'recherche actuellement un.e data scientist pour approfondir '\n",
      "                'les sujets de traitement du langage déjà enclenchés et '\n",
      "                'concevoir les algorithmes innovants de demain qui feront de '\n",
      "                'notre plateforme de tests à distance une référence en matière '\n",
      "                'd’intelligence artificielle appliquée à l’expérience '\n",
      "                'utilisateur (ux).\\n'\n",
      "                'missions:\\n'\n",
      "                'avec l’assistance du responsable de l’innovation, vous '\n",
      "                'assurerez les missions suivantes :\\n'\n",
      "                'concevoir et développer des nouveaux modèles de machine '\n",
      "                'learning / deep learning pour extraire de la valeur à partir '\n",
      "                'de l’ensemble des données de nos testeurs (vidéos et '\n",
      "                'questionnaires)\\n'\n",
      "                'consolider et faire évoluer les algorithmes de traitement du '\n",
      "                'langage (nlp) existants\\n'\n",
      "                'déployer les algorithmes en production et suivre l’évolution '\n",
      "                'de leurs performances au cours du temps\\n'\n",
      "                'surveiller l’activité et les performances de nos systèmes de '\n",
      "                'données, et participer ponctuellement à la maintenance '\n",
      "                'applicative de notre infrastructure data\\n'\n",
      "                'communiquer régulièrement avec l’ensemble des équipes lors de '\n",
      "                'réunions, capitaliser les nouveaux savoirs dans des documents '\n",
      "                'de recherche et écrire des articles de vulgarisation autour '\n",
      "                'du nlp sur notre blog\\n'\n",
      "                'assurer la veille technologique sur les sujets liés au nlp '\n",
      "                '(état de l’art, publications scientifiques, participation à '\n",
      "                'des conférences, meetups …)\\n'\n",
      "                'les étapes de conception et de réflexion autour des '\n",
      "                'algorithmes seront pour vous aussi importantes que les étapes '\n",
      "                'de développement du code et de restitution de l’information '\n",
      "                '(documentation, documents de recherche), vous serez ainsi '\n",
      "                'aguerri.e à pérenniser les logiques et les codes sources que '\n",
      "                'vous développerez.\\n'\n",
      "                'vous travaillerez également en étroite collaboration avec '\n",
      "                'l’équipe produit, nos ergonomes et nos chargé.e.s d’études '\n",
      "                'ux.\\n'\n",
      "                'notre stack data :\\n'\n",
      "                'environnements : linux, google cloud platform, kubernetes, '\n",
      "                'airflow, gitlab ci, jupyter notebooks\\n'\n",
      "                'langages & frameworks : python (flask, pandas, sklearn, '\n",
      "                'keras, torch, tensorflow …), scripts shell\\n'\n",
      "                'bases de données sql / nosql\\n'\n",
      "                'les + chez testapic\\n'\n",
      "                'bureaux dans le quartier de république\\n'\n",
      "                'un petit-dej en ton honneur et un sweat testapic le jour de '\n",
      "                'ton arrivée\\n'\n",
      "                'ambiance start-up\\n'\n",
      "                'profil recherché\\n'\n",
      "                'vous possédez un diplôme d’ingénieur ou un master 2 avec une '\n",
      "                'spécialisation dans le domaine de la data science et '\n",
      "                'l’informatique. vous êtes créatif.ve et entreprenant.e, et '\n",
      "                'disposez des compétences suivantes :\\n'\n",
      "                'vous êtes passionné.e par le nlp, vous avez déjà une première '\n",
      "                'expérience solide dans le domaine (de préférence plusieurs), '\n",
      "                'en particulier autour du développement d’algorithmes de deep '\n",
      "                'learning appliqués à ce domaine\\n'\n",
      "                'vous êtes entreprenant.e et force de proposition lorsqu’il '\n",
      "                's’agit de concevoir des algorithmes et vous n’hésitez pas à '\n",
      "                'parcourir la littérature scientifique pour dénicher les '\n",
      "                'algorithmes innovants les plus adaptés pour répondre à un '\n",
      "                'problème donné\\n'\n",
      "                'vous êtes à l’aise avec la programmation en python, avec les '\n",
      "                'concepts de programmation orientée objet et vous êtes capable '\n",
      "                'de vous adapter rapidement à de nouvelles technos\\n'\n",
      "                'vous êtes très sociable et avez une appétence particulière '\n",
      "                'pour vulgariser et présenter votre travail au sein d’équipes '\n",
      "                'pluridisciplinaires (direction, sales, ux, csm, dev, …). de '\n",
      "                'bonnes compétences rédactionnelles sont également '\n",
      "                'indispensables.\\n'\n",
      "                'vous avez soif d’apprendre et aimez les nouveaux challenges '\n",
      "                'techniques.',\n",
      " 'ID': 'p_3731724de24c12ed',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=3731724de24c12ed&fccid=21402e08e2082f06&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'pythonsqlnlp',\n",
      " 'Title': 'data scientist',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab8d2'),\n",
      " 'index': 154,\n",
      " 'level_0': 154}\n",
      "{'Company': \"siège de l'ap-hp\",\n",
      " 'Description': 'descriptif\\n'\n",
      "                'le pôle innovations & données au sein de la dsi :\\n'\n",
      "                '\\n'\n",
      "                'le pôle innovation et données, constitué d’environ 65 '\n",
      "                'personnes, a pour missions d’adresser les enjeux croissants '\n",
      "                'relatifs à l’accès et au traitement des données pour '\n",
      "                'l’innovation, la recherche, le pilotage et le développement '\n",
      "                'de la médecine de précision. le pôle est composé actuellement '\n",
      "                'de 6 domaines : \\uf0d8\\n'\n",
      "                '\\n'\n",
      "                'le domaine plateforme données massives ayant pour objectifs '\n",
      "                'de consolider, industrialiser et étendre les usages de la '\n",
      "                'plateforme big data de l’ap-hp. l’équipe est notamment '\n",
      "                'responsable de l’ingénierie des données, de l’administration '\n",
      "                'de l’infrastructure, et du développement d’outils '\n",
      "                'informatiques permettant l’exploitation des données en '\n",
      "                'adressant les besoins de la recherche, du pilotage et de '\n",
      "                'l’innovation. \\uf0d8\\n'\n",
      "                'le domaine recherche et expertise de données a pour objectif '\n",
      "                'de consolider la gouvernance institutionnelle des données en '\n",
      "                'lien avec la communauté médicale et de définir la stratégie '\n",
      "                'de standardisation et de mise en qualité des données. ce '\n",
      "                'domaine a pour objectif en lien avec la direction de la '\n",
      "                'recherche clinique la mise œuvre les solutions et outils '\n",
      "                'nécessaires pour la recherche. l’équipe construit une offre '\n",
      "                'de service à destination des chercheurs et cliniciens afin de '\n",
      "                'permettre l’essor de la recherche sur données et de la '\n",
      "                'recherche clinique à l’ap-hp.\\n'\n",
      "                '\\uf0d8 le domaine décisionnel – business intelligence est en '\n",
      "                'charge de mettre en œuvre les outils de business intelligence '\n",
      "                'pour les besoins de pilotage de l’activité de l’ap-hp. elle '\n",
      "                'est notamment responsable du développement d’indicateurs, de '\n",
      "                'tableaux de bord et de solutions de data-visualisation pour '\n",
      "                'les équipes de soins et les directions fonctionnelles. cette '\n",
      "                'équipe aura par ailleurs comme objectifs de stimuler les '\n",
      "                'usages de la donnée au sein des directions stratégiques du '\n",
      "                'siège et des groupes hospitalo-universitaires. \\uf0d8\\n'\n",
      "                'le domaine innovation a vocation à accompagner les projets '\n",
      "                'd’innovation autour de la donnée de la dsi et est responsable '\n",
      "                'du lab numérique de l’ap-hp permettant d’incuber des projets '\n",
      "                'numériques à forte valeur pour l’institution. l’équipe assure '\n",
      "                'la synergie de ces projets avec le reste de la dsi afin de '\n",
      "                'permettre leur intégration au sein des systèmes d’information '\n",
      "                'de production.\\n'\n",
      "                '\\uf0d8 la cellule opérationnelle bndmr, est chargée de '\n",
      "                'poursuivre le projet national confié à l’ap-hp dans le cadre '\n",
      "                'du plan national maladies rares 2. elle est ainsi responsable '\n",
      "                'du développement de bamara, de l’entrepôt bndmr, et de '\n",
      "                'l’offre de service aux centres et filières maladies rares. '\n",
      "                '\\uf0d8\\n'\n",
      "                'le domaine bio-informatique s’occupe de la mise en œuvre de '\n",
      "                'la plateforme bio-informatique, moabi, de l’ap-hp (outils '\n",
      "                'galaxy, groute, leaves), du déploiement de ces solutions '\n",
      "                'auprès des services de génétique, de la mise en place d’une '\n",
      "                'offre de service bio-informatique externe ainsi que du lien '\n",
      "                'resserré avec le plan france médecine génomique et la '\n",
      "                'plateforme seqoia.\\n'\n",
      "                '\\n'\n",
      "                'description du projet de labia :\\n'\n",
      "                '\\n'\n",
      "                'le pôle innovation et données comporte plusieurs équipes '\n",
      "                'travaillant directement à la constitution de bases de données '\n",
      "                'et au traitement de données massives avec notamment :\\n'\n",
      "                'l’entrepôt de données de santé (eds), principale base de '\n",
      "                'données de santé hébergée au sein de la plateforme données '\n",
      "                'massives de l’ap-hp, contient aujourd’hui les données '\n",
      "                'médicales de plus de 11 millions de patients (40 millions de '\n",
      "                'dossiers médicaux, plus de 10 millions de diagnostics, 181 '\n",
      "                'millions de résultats de laboratoires).\\n'\n",
      "                'la banque nationale de données maladies rares constitue la '\n",
      "                'base de données la plus importante sur les maladies rares en '\n",
      "                'france.\\n'\n",
      "                'la plateforme bioinformatique de l’ap-hp consolidant les '\n",
      "                'données de génétique des patients de l’ap-hp.\\n'\n",
      "                '\\n'\n",
      "                'avec l’accélération de ces différents projets, les besoins en '\n",
      "                'terme de sciences des données au sein même de l’équipe '\n",
      "                'innovation et données sont de plus en plus nombreux '\n",
      "                '(enrichissement des données, mise en place de pipelines de '\n",
      "                'traitements - nlp, anonymisation, génération de données '\n",
      "                'synthétiques, constitution de librairies datascience pour '\n",
      "                'appuyer l’exploitation des données…). la multiplication des '\n",
      "                'collaborations avec les universités partenaires et organismes '\n",
      "                'de recherche nécessite par ailleurs une forte expertise de '\n",
      "                'machine learning/deep learning au sein de l’équipe.\\n'\n",
      "                '\\n'\n",
      "                'nous souhaitons ainsi créer un pôle ia composé de '\n",
      "                'datascientists capables de suivre l’état de l’art et '\n",
      "                'd’adresser les enjeux de traitement des données pour ces '\n",
      "                'différents projets. vous aurez pour mission de constituer le '\n",
      "                'labia, de préciser ses missions, de poursuivre et d’engager '\n",
      "                'de nouveaux projets de recherche sur ces thématiques.\\n'\n",
      "                '\\n'\n",
      "                'composition de l’équipe :\\n'\n",
      "                '\\n'\n",
      "                'outre son/sa responsable, le labia aura vocation à compter '\n",
      "                '4-5 datascientists permanents travaillant en lien avec les '\n",
      "                'différentes équipes du domaine innovation et données et à '\n",
      "                'coordonner les datascientists de l’ap-hp travaillant sur '\n",
      "                'l’eds (soit 6 aujourd’hui). les collaborations de recherche '\n",
      "                'permettront par ailleurs d’encadrer les travaux d’étudiants '\n",
      "                'en thèse (déjà 2 aujourd’hui), des internes de santé publique '\n",
      "                'et des travaux de thèses de médecine.\\n'\n",
      "                '\\n'\n",
      "                'liaisons hiérarchiques:\\n'\n",
      "                '\\n'\n",
      "                'rattaché(e) à la directrice du département innovation et '\n",
      "                'données, vos missions seront transverses au département '\n",
      "                'innovation et données et au sein de l’ap-hp\\n'\n",
      "                '\\n'\n",
      "                'liaisons fonctionnelles:\\n'\n",
      "                '\\n'\n",
      "                'les membres de l’équipe innovations et données\\n'\n",
      "                'les collégiales de l’ap-hp, les unités de recherche clinique, '\n",
      "                'les équipes d’informatique médicale de l’ap-hp, les groupes '\n",
      "                'de travail métier et les référents recherche au sein des ghu\\n'\n",
      "                'la drci et les autres directions du siège (dst, defip, daj, '\n",
      "                'drh, etc)\\n'\n",
      "                'les partenaires institutionnels (asip, inca, institut '\n",
      "                'curie…)\\n'\n",
      "                'les tiers extérieurs partenaires des projets, notamment les '\n",
      "                'universités partenaires de l’ap-hp, les epst (inserm, inria, '\n",
      "                'cnrs, ces, etc), le health data hub\\n'\n",
      "                'les autres directions de la dsi\\n'\n",
      "                '\\n'\n",
      "                'activités:\\n'\n",
      "                '\\n'\n",
      "                'mission générale :\\n'\n",
      "                '\\n'\n",
      "                'le/la responsable du labia aura pour mission principale de '\n",
      "                'construire et de structurer cette nouvelle équipe.\\n'\n",
      "                '\\n'\n",
      "                'la labia aura notamment pour missions de mettre en œuvre des '\n",
      "                'méthodes, des techniques et des outils permettant d’analyser, '\n",
      "                'de synthétiser et traduire efficacement des données.\\n'\n",
      "                '\\n'\n",
      "                'un effort sera porté à la publication dans des revues '\n",
      "                'scientifiques de machine learning pour valoriser les travaux '\n",
      "                'réalisés.\\n'\n",
      "                '\\n'\n",
      "                'missions principales :\\n'\n",
      "                '\\n'\n",
      "                'constituer et manager une équipe de data scientists '\n",
      "                'appliquant/développant les techniques à l’état de l’art dans '\n",
      "                'le domaine de la data science.\\n'\n",
      "                'développer la r&d dans le champ du traitement de données '\n",
      "                'massives en santé en lien avec les instituts thématiques '\n",
      "                'd’ia, les universités et les chaires ia et santé dont l’ap-hp '\n",
      "                'est partenaire.\\n'\n",
      "                'industrialiser une chaine de traitement automatique des '\n",
      "                'langues (tal) au sein de la plateforme permettant de '\n",
      "                'désidentifier ou extraire de l’information des documents '\n",
      "                'cliniques.\\n'\n",
      "                'porter des projets de data science de bout en bout '\n",
      "                '(conception, prototypage, mise en production) permettant '\n",
      "                \"d'anticiper l'évolution de l’état de santé des patients, \"\n",
      "                'd’identifier des tendances concernant la prise en charge des '\n",
      "                'patients ou les résultats des soins.\\n'\n",
      "                'industrialiser des procédés d’analyse des données les plus '\n",
      "                'utiles et modéliser les résultats pour les rendre lisibles et '\n",
      "                'exploitables par les professionnels de santé, les chercheurs '\n",
      "                'ou les directions fonctionnelles (phénotypage, patients '\n",
      "                'similaires, indicateurs de tendances)\\n'\n",
      "                'animer la communauté de data science de l’ap-hp (6 data '\n",
      "                'scientists au sein des unités de recherche clinique) et de '\n",
      "                'l’écosystème en lien avec les partenaires académiques et '\n",
      "                'industriels de l’institution.\\n'\n",
      "                'coordonner l’appui analytique aux recherches réalisées sur '\n",
      "                'les données de la plateforme : études observationnelles '\n",
      "                'complexes (études épidémiologiques, études d’incidence, '\n",
      "                'analyse de comorbidités, études de corrélation entre facteurs '\n",
      "                'de risque et survenue de maladies ou de complications, études '\n",
      "                'de pratiques, études médico-économiques) ou '\n",
      "                'développement/évaluation d’algorithmes (ml/dl)\\n'\n",
      "                '\\n'\n",
      "                'quotite\\n'\n",
      "                '100 %\\n'\n",
      "                'horaires de travail\\n'\n",
      "                'cadre au forfait\\n'\n",
      "                'competences requises\\n'\n",
      "                'savoir-faire requis\\n'\n",
      "                'vous êtes experts en algorithmie, mathématiques appliquées et '\n",
      "                'statistiques et avez une passion pour l’ia et le machine '\n",
      "                'learning avec un vrai enthousiasme pour explorer et apprendre '\n",
      "                '(cours en ligne, papiers de recherche, compétitions kaggle, '\n",
      "                'portfolio git, etc.)\\n'\n",
      "                '\\n'\n",
      "                'vous avez de solides compétences en programmation '\n",
      "                'informatique (python, java, c/c++, javascript, scala, …), '\n",
      "                'avez une forte expérience en machine learning/deep learning.\\n'\n",
      "                '\\n'\n",
      "                'vous maitrisez les bases de données (sql, nosql, cassandra…), '\n",
      "                'les outils etl, les systèmes décisionnels (bi), les '\n",
      "                'technologies du big data permettant le traitement et la '\n",
      "                'manipulation de données, l’interface de développement '\n",
      "                'jupyterlab\\n'\n",
      "                '\\n'\n",
      "                'vous avez une bonne connaissance des frameworks commerciaux '\n",
      "                'ou open-source de data science (pandas, ml flow, tensorflow, '\n",
      "                'pytorch, scikit-learn, keras ,…) et êtes en capacité de '\n",
      "                'réaliser des analyses comparatives de ces solutions dans le '\n",
      "                'contexte de l’ap-hp\\n'\n",
      "                '\\n'\n",
      "                'vous avez la capacité de comprendre rapidement les enjeux '\n",
      "                'd’une organisation afin de créer et développer de nouvelles '\n",
      "                'solutions adaptées aux cas d’usage\\n'\n",
      "                '\\n'\n",
      "                'vous maitrisez les méthodes de développements agiles, savez '\n",
      "                'adopter une approche pragmatique des problèmes, pour créer '\n",
      "                'des outils utilisables en production rapidement, notamment en '\n",
      "                's’appuyant sur l’existant,\\n'\n",
      "                '\\n'\n",
      "                'vous avez une capacité à tester et expérimenter, comprendre '\n",
      "                'et modifier le code de programmes existants\\n'\n",
      "                '\\n'\n",
      "                'vous savez piloter, animer / communiquer, motiver une équipe '\n",
      "                'et avez de la pédagogie pour expliquer des concepts complexes '\n",
      "                'à des audiences non techniques.\\n'\n",
      "                '\\n'\n",
      "                'vous avez une très bonne connaissance du secteur de la '\n",
      "                'recherche dans les domaines de machine learning ou deep '\n",
      "                'learning\\n'\n",
      "                '\\n'\n",
      "                'vous êtes capable de rédiger ou de coordonner la rédaction '\n",
      "                'd’articles scientifiques dans le domaine du machine '\n",
      "                'learning/deep learning\\n'\n",
      "                '\\n'\n",
      "                'vous connaissez les standards d’interopérabilité dans le '\n",
      "                'domaine de la santé (ihe, hl7 fhir, cda, omop, cim, ccam, '\n",
      "                'loinc, snomed)\\n'\n",
      "                '\\n'\n",
      "                'vous parlez anglais couramment\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'pre-requis\\n'\n",
      "                '\\n'\n",
      "                'doctorat en informatique ou statistique, spécialisé dans la '\n",
      "                'data science ou intelligence artificielle ou en sciences '\n",
      "                '(mathématique, physique, sciences de la vie) avec formation '\n",
      "                'complémentaire en informatique.\\n'\n",
      "                'expérience professionnelle de 5 ans dans l’analyse de données '\n",
      "                'dans un environnement big data avec une expérience '\n",
      "                'significative de machine learning en production (aides '\n",
      "                'décisionnelles, détection de tendances, tal, etc) au sein '\n",
      "                'd’une dsi orientée données.\\n'\n",
      "                '\\n'\n",
      "                'qualités requises:\\n'\n",
      "                '\\n'\n",
      "                'passionné(e) par la data et les nouveaux usages\\n'\n",
      "                'organisé(e), méthodique, flexible et agile\\n'\n",
      "                'force de proposition, curieux et créatif\\n'\n",
      "                'doté(e) d’un bon esprit d’analyse, de synthèse, d’une grande '\n",
      "                'aisance orale et rédactionnelle\\n'\n",
      "                'avez d’excellentes aptitudes relationnelles et de '\n",
      "                \"communication, d'accompagnement au changement, une bonne \"\n",
      "                'capacité d’écoute et de vulgarisation, et une capacité '\n",
      "                'd’animation de groupes de travail\\n'\n",
      "                'savez communiquer efficacement sur l’avancement des tâches '\n",
      "                'auprès de votre hiérarchie\\n'\n",
      "                'personne à contacter\\n'\n",
      "                'elisa.salamanca@aphp.fr',\n",
      " 'ID': 'p_2546f72f27025e5b',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=2546f72f27025e5b&fccid=c7c2b887f99bc847&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'keras',\n",
      " 'Title': 'senior data scientist – responsable lab ia (2020-161)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab90d'),\n",
      " 'index': 213,\n",
      " 'level_0': 213}\n",
      "{'Company': 'axionable',\n",
      " 'Description': 'nous recherchons un·e data scientist, titulaire d’un '\n",
      "                'doctorat, pour contribuer à notre r&d interne en ia à '\n",
      "                'finalité durable.\\n'\n",
      "                'en soutien de notre directeur scientifique basé à montréal, '\n",
      "                'vos missions se concentrent sur :\\n'\n",
      "                'travailler sur des ensembles de données complexes et très '\n",
      "                'variés tels l’impact carbone, l’efficacité énergétique, '\n",
      "                'provenant de divers secteurs, pour résoudre des problèmes '\n",
      "                'concrets.\\n'\n",
      "                'réaliser une veille de l’état de l’art scientifique des '\n",
      "                'méthodes pertinentes pour nos objectifs de r&d.\\n'\n",
      "                'concevoir, développer et tester des solutions de science des '\n",
      "                'données pour notre r&d interne.\\n'\n",
      "                'contribuer à la rédaction de publications scientifiques à '\n",
      "                'présenter lors de réunions et de conférences.\\n'\n",
      "                'participer au montage de partenariats scientifiques et des '\n",
      "                'dossiers de financement associés.\\n'\n",
      "                'travailler dans un environnement multidisciplinaire avec '\n",
      "                'd’autres spécialistes en apprentissage automatique, en '\n",
      "                'ingénierie des données, et issus des métiers d’application.\\n'\n",
      "                'profil recherché\\n'\n",
      "                'axionable s’engage en faveur de l’égalité des chances, de la '\n",
      "                'diversité et de l’équité. nous encourageons tout candidat(e) '\n",
      "                'ayant l’expérience requise à postuler à nos offres.\\n'\n",
      "                'récemment diplômé.e d’un doctorat en apprentissage '\n",
      "                'automatique, statistiques appliquées, mathématiques '\n",
      "                'appliquées ou informatique.\\n'\n",
      "                'expérience en modélisation statistique et techniques '\n",
      "                'd’apprentissage automatique.\\n'\n",
      "                'connaissances des méthodes de nlp requise.\\n'\n",
      "                'expérience de programmation en python et / ou r.\\n'\n",
      "                'expérience dans l’application de méthodes de science des '\n",
      "                'données à des problèmes concrets.\\n'\n",
      "                'très bonnes capacités de travailler en équipe dans un '\n",
      "                'environnement fortement collaboratif.\\n'\n",
      "                'très bonnes capacités de présentation et de communication, '\n",
      "                'capacité à expliquer des concepts analytiques complexes à des '\n",
      "                'personnes d’autres domaines.\\n'\n",
      "                'forte autonomie, grande curiosité et passion pour les sujets '\n",
      "                'science des données/ ia.\\n'\n",
      "                'grande capacité d’écoute et d’apprentissage.\\n'\n",
      "                'capacité à synthétiser rapidement et à proposer des solutions '\n",
      "                'innovantes.\\n'\n",
      "                'français et anglais courant.',\n",
      " 'ID': 'p_f1fd7f1640cbb999',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=f1fd7f1640cbb999&fccid=2e44d52eaa305ec6&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'pythonnlp',\n",
      " 'Title': 'phd data scientist (f/h)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab91d'),\n",
      " 'index': 229,\n",
      " 'level_0': 229}\n",
      "{'Company': 'mirakl',\n",
      " 'Description': 'acteur majeur du marché des plateformes, mirakl fournit la '\n",
      "                'technologie et l’écosystème de partenaires nécessaires au '\n",
      "                'lancement d’une marketplace en ligne. mirakl, c’est…\\n'\n",
      "                'le leader mondial des solutions de marketplaces, partenaire '\n",
      "                'de la transformation digitale des plus grandes '\n",
      "                'multinationales\\n'\n",
      "                'une entreprise globale avec un siège à paris et plus de 250 '\n",
      "                'employés répartis dans les bureaux de paris, boston, londres, '\n",
      "                'munich, barcelone, stockholm et são paulo\\n'\n",
      "                'une structure en pleine croissance qui vient de lever 70 '\n",
      "                'millions de dollars dans le cadre d’un financement de série c '\n",
      "                'auprès d’investisseurs de premier plan comme bain capital '\n",
      "                'ventures, elaia et 83 north. ceci porte l’investissement '\n",
      "                'total à plus de 100 millions de dollars.\\n'\n",
      "                'plus de 200 projets b2b ou b2c dans le monde, pour permettre '\n",
      "                'à de grandes marques et entreprises d’élargir leur offre, de '\n",
      "                'vendre plus et de mieux comprendre leur marché : urban '\n",
      "                'outfitters, hewlett packard enterprise, best buy canada, '\n",
      "                'carrefour, siemens, toyota material handling usa, inc. et '\n",
      "                'walmart mexico…\\n'\n",
      "                'des valeurs fondamentales : innovate & inspire, satisfy & '\n",
      "                'empower clients, get things done, go above & beyond, and work '\n",
      "                'hard together.\\n'\n",
      "                'mirakl a augmenté ses effectifs de 200% au cours des deux '\n",
      "                'dernières années. en 2020, nous continuerons sur cette lancée '\n",
      "                'en recrutant les meilleurs profils. gartner prévoit que plus '\n",
      "                'de 60% des e-commerçants opteront pour une marketplace ou '\n",
      "                'incluront des vendeurs tiers dans leur écosystème de vente en '\n",
      "                'ligne d’ici à la fin 2020. pour soutenir cette mutation '\n",
      "                'profonde du marché et participer à notre développement, '\n",
      "                'mirakl recherche un(e) data scientist.\\n'\n",
      "                '\\n'\n",
      "                'a propos de mirakl labs\\n'\n",
      "                'avec une moyenne d’âge de 30 ans, mirakl labs représente la '\n",
      "                'moitié des effectifs de l’entreprise et est organisé en '\n",
      "                'petites \"feature teams\" (dev front/back, po, qa) de 7 à 10 '\n",
      "                'personnes. chacune travaille sur des applications et '\n",
      "                'micro-services spécifiques, elles sont donc autonomes et '\n",
      "                'attachent une grande importance à la qualité du code et '\n",
      "                'l’agilité. innovation, feedback et implication dans les '\n",
      "                'prises de décision sont au coeur de notre philosophie. ce qui '\n",
      "                'nous motive? l’amélioration continue. la prise d’initiatives '\n",
      "                'est donc encouragée et reconnue.\\n'\n",
      "                \"notre culture technique s'appuie sur la qualité du code avec \"\n",
      "                'des revues systématiques des pull-requests, une très bonne '\n",
      "                'couverture de tests automatisés et enfin l’intégration et la '\n",
      "                'livraison en continu avec des mises en production quasi '\n",
      "                'quotidiennes.\\n'\n",
      "                'nous sommes également activement impliqués au sein de la '\n",
      "                'communauté java parisienne car nous sponsorisons le paris '\n",
      "                'jug, devoxx fr; nous mettons à disposition nos locaux pour '\n",
      "                \"l'organisation de bbl et bientôt des meetups.\\n\"\n",
      "                '\\n'\n",
      "                'a propos du job\\n'\n",
      "                'intégré(e) dans une équipe data science de trois personnes, '\n",
      "                'votre principale mission sera de prototyper, itérer, et '\n",
      "                'mettre en production des algorithmes en collaboration avec '\n",
      "                'les ml engineers et les équipes produit. les sujets que vous '\n",
      "                'traiterez auront un vrai impact sur nos marketplaces : '\n",
      "                'l’ambition est d’exploiter au maximum nos données riches et '\n",
      "                'variées afin de driver leur business.\\n'\n",
      "                'des exemples de projets actuels et futurs à fort impact :\\n'\n",
      "                'catégorisation de produits\\n'\n",
      "                'extraction de features sur les produits\\n'\n",
      "                'détection de comportements frauduleux\\n'\n",
      "                'estimation de la date de livraison\\n'\n",
      "                'monitoring de la qualité de services des vendeurs\\n'\n",
      "                'prédiction de produits tendance\\n'\n",
      "                'aide/suggestion de réponses au customer service\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'ce qu’il y a pour vous dans ce job :\\n'\n",
      "                'implémenter des algorithmes qui auront un impact visible sur '\n",
      "                'une 200+ marketplaces dans 40 pays, avec des millions de '\n",
      "                'produits / marketplace\\n'\n",
      "                'des sujets divers et variés (heuristiques, nlp, deep '\n",
      "                'learning, image processing, etc.)\\n'\n",
      "                'une vraie autonomie et responsabilité dans les projets\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'notre super stack et nos outils\\n'\n",
      "                'python, r, keras, databricks, spark, aws (amazon redshift, '\n",
      "                's3, etc.), sql, airflow\\n'\n",
      "                '\\n'\n",
      "                'au quotidien, vous allez :\\n'\n",
      "                'analyser, nettoyer les données, prototyper des algorithmes\\n'\n",
      "                'les mettre en production en collaboration avec les ml '\n",
      "                'engineers et les feature teams\\n'\n",
      "                'faire des dashboards afin de monitorer la production\\n'\n",
      "                'présenter les résultats au weekly data science\\n'\n",
      "                'participer aux sessions de brainstormings de l’équipe\\n'\n",
      "                'échanger avec les autres équipes pour bénéficier de leur '\n",
      "                'expertise\\n'\n",
      "                '\\n'\n",
      "                'requirements\\n'\n",
      "                'vous aimerez ce job si :\\n'\n",
      "                'vous êtes titulaire d’un diplôme d’ingénieur avec une '\n",
      "                'spécialisation en mathématiques appliquées, machine learning '\n",
      "                'ou toute autre formation similaire\\n'\n",
      "                \"vous avez 2 à 3 ans d'expérience minimum en tant que data \"\n",
      "                'scientist\\n'\n",
      "                'vous avez une expérience significative en machine learning '\n",
      "                'appliqué en entreprise\\n'\n",
      "                'vous avez une expérience en développement spark\\n'\n",
      "                'vous êtes pragmatique et data-driven\\n'\n",
      "                'vous choisissez le bon outil pour la bonne problématique\\n'\n",
      "                'vous avez l’ownership du projet : du nettoyage de données '\n",
      "                'jusqu’à l’intégration de l’algorithme dans un produit '\n",
      "                'existant\\n'\n",
      "                'vous êtes autonome et avez un très bon esprit d’équipe\\n'\n",
      "                'esprit positif, respect et bienveillance font partie de vos '\n",
      "                'valeurs\\n'\n",
      "                'benefits\\n'\n",
      "                'super locaux flambants neufs au plein cœur de paris\\n'\n",
      "                '50% du transport remboursé\\n'\n",
      "                \"mutuelle payée par l'entreprise\\n\"\n",
      "                '10€ de tickets restaurant par jour\\n'\n",
      "                \"remboursement de l'abonnement internet et téléphonie mobile\",\n",
      " 'ID': 'p_b4db59e2616003d8',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=b4db59e2616003d8&fccid=8912fd9d8d9fa5ef&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'javaaws',\n",
      " 'Title': 'data scientist',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab93d'),\n",
      " 'index': 261,\n",
      " 'level_0': 261}\n",
      "{'Company': 'harnham',\n",
      " 'Description': 'data scientist - jeune docteur / phd\\n'\n",
      "                'paris, france\\n'\n",
      "                '40-50k\\n'\n",
      "                '\\n'\n",
      "                'cette belle startup de 2 ans vient de lever plusieurs '\n",
      "                \"millions d'euros pour continuer sa croissance. elle a \"\n",
      "                'construit une plateforme saas qui accompagne les entreprises '\n",
      "                \"dans leurs projets it grâce à de l'intelligence artificielle \"\n",
      "                'et du machine learning.\\n'\n",
      "                'ce poste offre la possibilité de travailler sur des sujets '\n",
      "                'nlp et des sujets plus larges de machine learning, entouré '\n",
      "                \"d'une équipe data science en place.\\n\"\n",
      "                'le poste:\\n'\n",
      "                'encadré par le cto de la société, vous travaillerez avec une '\n",
      "                'équipe de profils seniors et juniors basé sur paris\\n'\n",
      "                'votre background académique et technique vous permettra '\n",
      "                \"d'apporter votre expertise du côté data science sur des \"\n",
      "                'sujets r&d machine learning (utilisation de python à '\n",
      "                'prévoir)\\n'\n",
      "                'vous travaillerez sur divers algo ml pour optimiser la '\n",
      "                'plateforme sur des problématiques clés dans la roadmap data '\n",
      "                'de la société\\n'\n",
      "                '\\n'\n",
      "                'votre profil:\\n'\n",
      "                'un doctorat en computer science ou data science/nlp ou '\n",
      "                'domaine relié\\n'\n",
      "                \"vous êtes en recherche de votre premier cdi (afin d'être \"\n",
      "                'éligible au cir)\\n'\n",
      "                'expertise sur python ou c++\\n'\n",
      "                'force de proposition et bon communicant\\n'\n",
      "                '\\n'\n",
      "                'comment postuler :\\n'\n",
      "                'si vous êtes intéressé(e), merci de faire part de votre cv '\n",
      "                'via ce site / postuler.',\n",
      " 'ID': 'p_2b77ee7a20997902',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=2b77ee7a20997902&fccid=d72eb0548d91249c&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '40 000 € - 50 000 € par an',\n",
      " 'Skills': 'pythonnlp',\n",
      " 'Title': 'data scientist - jeune docteur / phd',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab949'),\n",
      " 'index': 273,\n",
      " 'level_0': 273}\n",
      "{'Company': 'harnham',\n",
      " 'Description': 'senior data scientist\\n'\n",
      "                'paris, france\\n'\n",
      "                '45-55k\\n'\n",
      "                'leader du media publishing sur internet (vous reconnaitrez '\n",
      "                'certainement leur contenu), la société grandit son pôle data '\n",
      "                \"et recherche aujourd'hui un data scientist experimenté. ce \"\n",
      "                'poste offre la possibilité de travailler sur des sujets '\n",
      "                'divers (nlp, machine learning, advanced analytics...) sur '\n",
      "                'leur plateforme tech qui gère leur contenu media et video, '\n",
      "                \"entouré d'une équipe data science en place. aujourd'hui très \"\n",
      "                \"solide sur le plan financier, avec des records d'audience et \"\n",
      "                \"d'abonnés, les projets data science seront riches et divers.\\n\"\n",
      "                'le poste:\\n'\n",
      "                'encadré par le head of data de la société, vous travaillerez '\n",
      "                'avec une équipe de profils seniors et juniors basé sur paris '\n",
      "                'et en remote\\n'\n",
      "                \"votre background technique vous permettra d'apporter votre \"\n",
      "                'expertise du côté data science, machine learning et '\n",
      "                'intelligence artificielle - la société utilise python '\n",
      "                'actuellement\\n'\n",
      "                'votre seniorité technique vous permettra de diffuser vos '\n",
      "                'idées pour continuer à développer et optimiser les '\n",
      "                'plateformes et le succès du contenu publié (on peut donc '\n",
      "                'penser à divers projets machine learning, de la prédiction, '\n",
      "                'des algos poussés qui automatisent les process, du nlp ...)\\n'\n",
      "                '\\n'\n",
      "                'votre profil:\\n'\n",
      "                'un background académique (bac+5 et plus) orienté '\n",
      "                'stats/maths/finance ou domaine relié\\n'\n",
      "                'expérience industrielle en tant que data scientist\\n'\n",
      "                'expertise sur python, sql, et expérience avancée en machine '\n",
      "                'learning\\n'\n",
      "                'comment postuler:\\n'\n",
      "                'merci de me faire part de votre cv à jour et je vous '\n",
      "                'recontacterai au plus vite.',\n",
      " 'ID': 'p_89ce7c497b4625f2',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=89ce7c497b4625f2&fccid=d72eb0548d91249c&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '45 000 € - 55 000 € par an',\n",
      " 'Skills': 'pythonnlp',\n",
      " 'Title': 'senior data scientist - tech startup',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab94b'),\n",
      " 'index': 275,\n",
      " 'level_0': 275}\n",
      "{'Company': 'sept lieues',\n",
      " 'Description': 'pure player international leader sur son marché, spécialisé '\n",
      "                'dans la conception de sites e-commerce.\\n'\n",
      "                'solutions développées from scratch en interne.\\n'\n",
      "                'le poste / les missions\\n'\n",
      "                \"vous rejoindrez l'équipe data de l'entreprise en tant que \"\n",
      "                'data scientist\\n'\n",
      "                'vous travaillerez dans un environnement international.\\n'\n",
      "                '\\n'\n",
      "                'vos principales missions:\\n'\n",
      "                \"etude de l'état de l'art\\n\"\n",
      "                'traitement du langage naturel\\n'\n",
      "                'traitement de gros volume données\\n'\n",
      "                \"développement d'algorithmes\\n\"\n",
      "                '\\n'\n",
      "                'profil recherché\\n'\n",
      "                \"issu(e) d'une école d'ingénieur ou équivalent, vous justifiez \"\n",
      "                \"d'une expérience de minimum 2 ans sur un poste similaire.\\n\"\n",
      "                'vous disposez de connaissances en nlp, mathématiques, et '\n",
      "                'problématiques relatives au e-commerce.\\n'\n",
      "                'vous maîtrisez python, java et scala.',\n",
      " 'ID': 'p_cae7f1b3f201eb31',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=cae7f1b3f201eb31&fccid=d98bfa22633409bb&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'java',\n",
      " 'Title': 'data scientist - nlp',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab964'),\n",
      " 'index': 300,\n",
      " 'level_0': 300}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'soyez alerté de la prochaine offre similaire en cliquant '\n",
      "                'ici.\\n'\n",
      "                'consultant data science on site pour un jeune cabinet de '\n",
      "                'conseil prometteur\\n'\n",
      "                'offre publiée le 22-06-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data engineer hadoop spark\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'technologies bigquery\\n'\n",
      "                'technologies data studio\\n'\n",
      "                'technologies google analytics\\n'\n",
      "                'technologies google cloud plateform\\n'\n",
      "                'technologies machine learning\\n'\n",
      "                'technologies nlp\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies qlikview\\n'\n",
      "                'expérience jeune à dipl me\\n'\n",
      "                'expérience 1 à 2 ans\\n'\n",
      "                'expérience 3 à 5 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 44k€\\n'\n",
      "                'max 57k€\\n'\n",
      "                'la startup : un acteur du conseil spécialisé dans le '\n",
      "                'marketing digital et la data\\n'\n",
      "                'une top équipe : grandes écoles et anciens de cabinets de '\n",
      "                'conseil\\n'\n",
      "                'une clientèle diversifiée auprès de différents acteurs : la '\n",
      "                'française des jeux, groupe bayard, kenzo, ovh,\\n'\n",
      "                'boardriders, vente-privée.com, …\\n'\n",
      "                'des locaux au coeur de paris\\n'\n",
      "                'un cabinet en pleine croissance, intégré à un grand groupe en '\n",
      "                '2018 (agence digitale présente dans 15 pays)\\n'\n",
      "                'une dimension entrepreneuriale forte (culture, autonomie sur '\n",
      "                'les missions, valeurs, petit effectif)\\n'\n",
      "                'un projet early stage où avoir de l’impact (10 à 30 '\n",
      "                'personnes)\\n'\n",
      "                'créé en 2015\\n'\n",
      "                'environnement technique : nlp, machine learning, bigquery, '\n",
      "                'google cloud platform, qlikview, tableau, data studio, sql, '\n",
      "                'python\\n'\n",
      "                '\\n'\n",
      "                'votre mission : consultant data science on site\\n'\n",
      "                'au sein du pôle marketing science, vous intervenez sur des '\n",
      "                \"problématiques d'analyses marketing et notamment de \"\n",
      "                \"segmentation, d'analyse de performances de campagnes, \"\n",
      "                \"d'analyse du parcours client, de scorings, d'attribution, \"\n",
      "                'prédiction, de flux de données et automation, de '\n",
      "                'visualisation, … pour ce faire, vous :\\n'\n",
      "                'utilisez des techiques avancées de modélisations de données '\n",
      "                \"et d'analyses statistiques\\n\"\n",
      "                'restituez les données sous forme de data visualisation\\n'\n",
      "                \"participez au développment des méthodologies d'analyse du \"\n",
      "                'cabinet et à son positionnement technologique avant gardiste\\n'\n",
      "                'a noter : des déplacements ponctuels chez le client peuvent '\n",
      "                'être demandés.\\n'\n",
      "                '\\n'\n",
      "                'votre profil :\\n'\n",
      "                \"vous êtes diplômé d'une grande école de commerce, \"\n",
      "                \"d'ingénieurs ou équivalent\\n\"\n",
      "                \"diposez au moins d'une première expérience (stages compris)et \"\n",
      "                \"jusqu'à 3 ans expérience sur un ou plusieurs des sujets \"\n",
      "                'suivants :\\n'\n",
      "                \"data engineering : constructions d'infrastrures de données \"\n",
      "                'basées sur le cloud, flux de données entre différents outils\\n'\n",
      "                'data science : algorithmie, machine learing, analyse '\n",
      "                'descriptive et prédictive\\n'\n",
      "                'dataviz : dashboard adaptés aux enjeux opérationnels et '\n",
      "                'managériaux\\n'\n",
      "                'vous maîtrisez google cloud platform et des langages sql et '\n",
      "                'python\\n'\n",
      "                'vous êtes autonome et êtes force de proposition\\n'\n",
      "                'vous avez la volonté d’apprendre et de monter en compétences\\n'\n",
      "                '\\n'\n",
      "                'vos plus\\n'\n",
      "                'vous avez une première expertise conseil\\n'\n",
      "                'vous avez des connaissances sur les briques techniques de '\n",
      "                'google cloud platform\\n'\n",
      "                'vous maîtrisez un ou plusieurs outils de dataviz\\n'\n",
      "                '\\n'\n",
      "                'modalités :\\n'\n",
      "                'package 44 à 57k€ (variable selon profil – dont 2k€ de '\n",
      "                'variable)\\n'\n",
      "                'rtt : 10 jours\\n'\n",
      "                'jours de congés offerts ponctuellement\\n'\n",
      "                'petit déjeuners tous les lundis et panier de fruits\\n'\n",
      "                'carte lunchr\\n'\n",
      "                'mutuelle\\n'\n",
      "                '\\n'\n",
      "                'sélectionné par deborah peter\\n'\n",
      "                'spécialiste infra / devops / qa\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_bb03ec53831b40cb',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=bb03ec53831b40cb&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '44 000 € - 57 000 € par an',\n",
      " 'Skills': 'sql',\n",
      " 'Title': 'consultant data science on site pour un jeune cabinet de conseil '\n",
      "          'prometteur',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab98d'),\n",
      " 'index': 341,\n",
      " 'level_0': 341}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'soyez alerté de la prochaine offre similaire en cliquant '\n",
      "                'ici.\\n'\n",
      "                'data scientist phd pour révolutionner le monde de la '\n",
      "                'logistique automobile (cir)\\n'\n",
      "                'offre publiée le 22-06-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 21 à 50\\n'\n",
      "                'expérience 1 à 2 ans\\n'\n",
      "                'expérience 3 à 5 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 70k€\\n'\n",
      "                'max 80k€\\n'\n",
      "                \"l'entreprise : un acteur dans la logistique automobile\\n\"\n",
      "                \"l'entreprise propose des solutions simples pour déplacer un \"\n",
      "                \"véhicule en s'appuyant sur un réseau de :\\n\"\n",
      "                'convoyeurs professionels\\n'\n",
      "                'particuliers\\n'\n",
      "                'transporteurs\\n'\n",
      "                'quelques infos :\\n'\n",
      "                'créée en 2012\\n'\n",
      "                'ambition de devenir leader européen\\n'\n",
      "                'clients grands comptes : avis, europcar, citroën,...\\n'\n",
      "                \"plusieurs millions d'euro levés depuis la création\\n\"\n",
      "                'forte croissance\\n'\n",
      "                'bienveillance, entre-aide et solidarité sont les valeurs qui '\n",
      "                'la définissent !\\n'\n",
      "                \"environnement technique de l'entreprise: sql, gcp, node.js, \"\n",
      "                'php, react.js, ....\\n'\n",
      "                '\\n'\n",
      "                \"votre mission : developper la data science dans l'entreprise\\n\"\n",
      "                'face à la croissance du réseau de convoyeurs professionnels '\n",
      "                \"(plus d'un millier) vous aurez pour objectif de contribuer à \"\n",
      "                \"la mise en place d'outils permettant d'optimiser les enjeux \"\n",
      "                'opérationnels.\\n'\n",
      "                'pour cela, vous :\\n'\n",
      "                'mettez en place des outils data science\\n'\n",
      "                'vous apportez votre bagage technique, peut importe vos '\n",
      "                'langages de prédilection\\n'\n",
      "                \"construisez des algorithmes d'analyses prédictives, scoring, \"\n",
      "                'machine learning, …\\n'\n",
      "                'restituez les données sous forme de data visualisation '\n",
      "                'adaptés aux enjeux opérationnels\\n'\n",
      "                '\\n'\n",
      "                'votre profil : data scientist\\n'\n",
      "                \"poste proposé dans le cadre d'un cir\\n\"\n",
      "                'vous êtes diplômé d’une grande école d’ingénieurs ou '\n",
      "                'équivalent\\n'\n",
      "                'vous êtes titulaire d’un doctorat et n’avez jamais été '\n",
      "                'embauché en cdi après l’obtention de votre thèse (contrainte '\n",
      "                'impérative pour respecter les critères du cir)\\n'\n",
      "                'vous avez une bonne compréhension des enjeux business\\n'\n",
      "                'vous êtes autonome et êtes force de proposition\\n'\n",
      "                'vous êtes capable de mener des projets de bout en bout\\n'\n",
      "                '\\n'\n",
      "                'modalités :\\n'\n",
      "                'package 65 à 75 k€\\n'\n",
      "                'paris intra-muros\\n'\n",
      "                '\\n'\n",
      "                'sélectionné par\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_5cbd4e86133e5d38',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=5cbd4e86133e5d38&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '65 000 € - 75 000 € par an',\n",
      " 'Skills': '',\n",
      " 'Title': 'data scientist phd pour révolutionner le monde de la logistique '\n",
      "          'automobile (cir)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab98e'),\n",
      " 'index': 342,\n",
      " 'level_0': 342}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'soyez alerté de la prochaine offre similaire en cliquant '\n",
      "                'ici.\\n'\n",
      "                'senior data & analytics manager | 75-100 k€\\n'\n",
      "                'offre publiée le 24-06-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction head of data management\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'fonction data analyst sql r tableau\\n'\n",
      "                'fonction web data analyst analytics tag\\n'\n",
      "                'fonction data manager sql python\\n'\n",
      "                'teletravail ponctuel\\n'\n",
      "                'lead manager responsable\\n'\n",
      "                '1\\n'\n",
      "                'technologies aws\\n'\n",
      "                'technologies google analytics\\n'\n",
      "                'technologies google cloud plateform\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies r\\n'\n",
      "                'technologies sql\\n'\n",
      "                'technologies tableau\\n'\n",
      "                'expérience 6 à 10 ans\\n'\n",
      "                'expérience plus de 10 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'max 100k€\\n'\n",
      "                'la startup : un acteur proposant une application dans la '\n",
      "                'cybersécurité qui cartonne au niveau mondial\\n'\n",
      "                'effectif : 140 personnes\\n'\n",
      "                '10+ millions d’utilisateurs (dont 50% aux us)\\n'\n",
      "                '50+gb de données traitées par jour\\n'\n",
      "                '100+m€ de levée de fonds\\n'\n",
      "                'clients : 50 000 entreprises utilisent la solution\\n'\n",
      "                'les + de cette entreprise ?\\n'\n",
      "                'une startup pure tech, qui ambitionne d’être l’acteur n°1 '\n",
      "                'mondial sur un sujet qui touche beaucoup d’entre nous.\\n'\n",
      "                '\\n'\n",
      "                'ta mission : manager l’équipe data à paris\\n'\n",
      "                'sous la responsabilité du head of data à new york, tes '\n",
      "                'missions seront :\\n'\n",
      "                'management :\\n'\n",
      "                'accompagner ton équipe pour couvrir tout le cycle de la '\n",
      "                'donnée (de la collecte aux recommandations business)\\n'\n",
      "                'etre le point de contact principal au sein de l’équipe data\\n'\n",
      "                'analyses :\\n'\n",
      "                'faire des analyses complexes et créer des tableaux de bord '\n",
      "                'décisionnels\\n'\n",
      "                'construire de nouveaux modèles : segmentation client, '\n",
      "                'prédictions de comportements, …\\n'\n",
      "                'accompagner les différente équipes métiers (produit, '\n",
      "                'marketing, …) et leur proposer des recommandations\\n'\n",
      "                'les + de ce poste ?\\n'\n",
      "                'tu vas être amené à rapidement développer ton équipe (10aine '\n",
      "                'de recrutements prévus à court terme)\\n'\n",
      "                '\\n'\n",
      "                'ton profil : lead data analyst / manager data ou analytics\\n'\n",
      "                'tu as un bac+5 de type grande école d’ingénieur\\n'\n",
      "                'tu as 5+ ans d’expérience en sql et les bases de données '\n",
      "                'relationnelles (mysql, bigquery, redshift, …)\\n'\n",
      "                'tu maitrises les outils de dataviz\\n'\n",
      "                'tu as 2+ années d’expérience en langage script (python, '\n",
      "                'javascript, ruby, …)\\n'\n",
      "                'tu as 3+ années d’expérience en management d’équipe\\n'\n",
      "                'tes + à toi ?\\n'\n",
      "                'tu as de l’expérience sur des outils tels que r, sas, …\\n'\n",
      "                'modalités\\n'\n",
      "                'salaire entre : 75 à 100 k€\\n'\n",
      "                'avantages : stock options / rtt / mutuelle / tickets '\n",
      "                'restaurants / ce\\n'\n",
      "                'locaux situés en plein coeur de paris\\n'\n",
      "                'déplacements 3-4 fois / an à ny\\n'\n",
      "                '\\n'\n",
      "                'sélectionné par thomas bénard\\n'\n",
      "                'ceo\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_b28ff5fadba02e00',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=b28ff5fadba02e00&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'sql',\n",
      " 'Title': 'senior data & analytics manager',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab98f'),\n",
      " 'index': 343,\n",
      " 'level_0': 343}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'soyez alerté de la prochaine offre similaire en cliquant '\n",
      "                'ici.\\n'\n",
      "                'data scientist/engineer pour un acteur majeur du secteur de '\n",
      "                'la mode\\n'\n",
      "                'offre publiée le 12-02-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data engineer hadoop spark\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 51 à 200\\n'\n",
      "                '2\\n'\n",
      "                'technologies aws\\n'\n",
      "                'technologies javascript\\n'\n",
      "                'technologies kafka\\n'\n",
      "                'technologies php\\n'\n",
      "                'expérience 1 à 2 ans\\n'\n",
      "                'expérience 3 à 5 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 58k€\\n'\n",
      "                'max 66k€\\n'\n",
      "                'l’entreprise : un acteur majeur du secteur de la mode\\n'\n",
      "                'scale up à l’esprit start up (agile)\\n'\n",
      "                'digitale native\\n'\n",
      "                'volumétrie des données conséquente\\n'\n",
      "                'une présence internationale (boutiques physiques en france, '\n",
      "                'uk, us)\\n'\n",
      "                'des locaux au cœur de paris (2ème arrondissement)\\n'\n",
      "                'stack technique : aws, kafka, big data, php / symfony, ...\\n'\n",
      "                '\\n'\n",
      "                \"mission : contribuer à la mise en place d'outils permettant \"\n",
      "                \"d'optimiser les enjeux big data de la société\\n\"\n",
      "                'directement rattaché au cto, vous collaborerez avec les '\n",
      "                \"équipes produits et aurez pour missions de / d' :\\n\"\n",
      "                \"participer à la définition de cas d'usages de manière à \"\n",
      "                \"optimiser l'infrastructure\\n\"\n",
      "                'développer et implémenter des outils permettant de collecter '\n",
      "                'les données\\n'\n",
      "                'intervenir sur une grande volumétie de données (fort contexte '\n",
      "                'big data)\\n'\n",
      "                \"construire des algorithmes d'analyses prédictives, scoring, \"\n",
      "                \"... des ventes dans l'infrastructure cible\\n\"\n",
      "                'assurer l’ingestion et l’exposition des données dans '\n",
      "                'l’infrastructure\\n'\n",
      "                'restituez les données sous forme de data visualisation\\n'\n",
      "                'infuser vos connaissances techniques avec le reste de '\n",
      "                \"l'équipe technique\\n\"\n",
      "                'votre profil : data scientist/ engineer\\n'\n",
      "                'vous êtes diplômé(e) d’une grande école d’ingénieur\\n'\n",
      "                'vous avez une expérience réussie de 2 / 3 ans sur un poste '\n",
      "                'similaire\\n'\n",
      "                'vous êtes autonome et force de proposition\\n'\n",
      "                'vous êtes capable de mener des projets de bout en bout\\n'\n",
      "                'vous aimez les défis techniques et souhaitez apporter vos '\n",
      "                'connaissances techniques dans un contexte challengeant\\n'\n",
      "                'modalités :\\n'\n",
      "                'rémunération attractive selon profil de 58 - 66 k€ (+ rtt + '\n",
      "                'ticket restaurants + transport)\\n'\n",
      "                'bureaux situés en plein coeur de paris\\n'\n",
      "                'process de recrutement : call avec dr + call avec cto + 3 '\n",
      "                'entretiens onsite\\n'\n",
      "                '\\n'\n",
      "                'pour en savoir plus : ophelie@datarecrutement.fr\\n'\n",
      "                '\\n'\n",
      "                'sélectionné par ophélie gaio\\n'\n",
      "                'spécialiste back-end\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_6b7846235d130fb1',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=6b7846235d130fb1&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '58 000 € - 66 000 € par an',\n",
      " 'Skills': '',\n",
      " 'Title': 'data scientist/engineer pour un acteur majeur du secteur de la mode',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab990'),\n",
      " 'index': 344,\n",
      " 'level_0': 344}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'offre publiée le 10-07-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction head of data management\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 5 à 001\\n'\n",
      "                'teletravail partiel apres une periode\\n'\n",
      "                'lead manager responsable\\n'\n",
      "                'technologies agile\\n'\n",
      "                'technologies elastic search\\n'\n",
      "                'technologies git\\n'\n",
      "                'technologies machine learning\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies spark\\n'\n",
      "                'expérience 6 à 10 ans\\n'\n",
      "                'expérience plus de 10 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 70k€\\n'\n",
      "                'max 100k€\\n'\n",
      "                '\\n'\n",
      "                \"l'entreprise : leader de l'assurance\\n\"\n",
      "                \"l'entreprise est le leader français et européen de \"\n",
      "                \"l'assurance et des services financiers. elle cherche \"\n",
      "                \"aujourd'hui à perfectionner et diversifier ses services en \"\n",
      "                'recrutant de nouveaux collaborateurs en data science.\\n'\n",
      "                'quelques informations :\\n'\n",
      "                \"plus de 20 ans d'expertise\\n\"\n",
      "                'effectif big data / ia / data science : 35 personnes (20 '\n",
      "                'personnes en cdi, 15 personnes en freelance)\\n'\n",
      "                'plus de 5 millions de clients\\n'\n",
      "                \"plus de 12 millions de chiffre d'affaires\\n\"\n",
      "                'plus de 10000 collaborateurs partout en france\\n'\n",
      "                \"notre avis chez data recrutement : c'est une belle \"\n",
      "                \"opportunité au sein d'une entreprise qui évolue dans un \"\n",
      "                'contexte de big data. les challenges sont intéressants et les '\n",
      "                \"perspectives d'évolution importantes.\\n\"\n",
      "                'vos missions : manager, accompagner, communiquer, développer\\n'\n",
      "                \"au sein d'une équipe big data et intelligence artificielle de \"\n",
      "                '35 personnes vous aurez à :\\n'\n",
      "                'manager 4 ou 5 data scientist dans un premier temps (une '\n",
      "                'dizaine dans les mois à venir)\\n'\n",
      "                'valider les démarches statistiques et la qualité des travaux '\n",
      "                'de votre équipe\\n'\n",
      "                \"vous impliquer dans la technique lorsqu'il le faudra\\n\"\n",
      "                'assurer le suivi, le coaching et le conseil auprès de vos '\n",
      "                'collaborateurs\\n'\n",
      "                'participer aux recrutements de vos futurs data scientist\\n'\n",
      "                'être le lien entre les équipes métiers et la data science et '\n",
      "                'comprendre les problématiques business\\n'\n",
      "                'répartition des tâches :\\n'\n",
      "                '50% de coaching et management\\n'\n",
      "                '20% de technique\\n'\n",
      "                '10% de rh\\n'\n",
      "                '20% de réunion vision stratégique et technique\\n'\n",
      "                'votre profil : lead data scientist\\n'\n",
      "                'compétences nécessaires :\\n'\n",
      "                \"vous êtes idéalement issu(e) d'une formation bac+5 (ingénieur \"\n",
      "                \"ou scientifique) ou d'un doctorat (phd)\\n\"\n",
      "                \"fort(e) d'au moins 7 ans d'expérience en data science vous \"\n",
      "                'avez un excellent niveau technique\\n'\n",
      "                'vous avez déjà managé une équipe de data scientist\\n'\n",
      "                'python, pyspark sont vos technologies de prédilection\\n'\n",
      "                'vous parlez anglais (écrit et oral)\\n'\n",
      "                'compétences appréciées :\\n'\n",
      "                'vous avez une expérience dans un grand groupe ou/et dans '\n",
      "                \"l'assurance\\n\"\n",
      "                'la data engineering ne vous est pas inconnue\\n'\n",
      "                'modalités :\\n'\n",
      "                'rémunération attractive : 70/100k€ + variable + rtt (18 '\n",
      "                'jours)\\n'\n",
      "                'locaux : paris - la défense\\n'\n",
      "                'processus de recrutement :\\n'\n",
      "                'entretien en vidéoconférence avec un lead data scientist\\n'\n",
      "                'test technique à distance (1h)\\n'\n",
      "                'entretien physique avec le head of data et d’autres personnes '\n",
      "                'de l’équipe\\n'\n",
      "                'entretien en physique avec le n+2\\n'\n",
      "                'entretien rh\\n'\n",
      "                'pour en savoir plus : thomas.gourmelon@datarecrutement.fr\\n'\n",
      "                'merci d’envoyer au plus vite votre cv / votre profil linkedin '\n",
      "                'par e-mail avec comme objet « manager data scientist '\n",
      "                'assurance » à thomas gourmelon '\n",
      "                '(thomas.gourmelon@datarecrutement.fr), responsable du pôle '\n",
      "                'javascript & mobile au sein de data recrutement.\\n'\n",
      "                'sélectionné par thomas gourmelon\\n'\n",
      "                'spécialiste python, ruby, go & data scientist\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_c3f58d8cd77e7a08',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=c3f58d8cd77e7a08&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '70 000 € - 100 000 € par an',\n",
      " 'Skills': '',\n",
      " 'Title': 'manager data scientist (10 managés, équipe big data et ia)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab991'),\n",
      " 'index': 345,\n",
      " 'level_0': 345}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'soyez alerté de la prochaine offre similaire en cliquant '\n",
      "                'ici.\\n'\n",
      "                \"directeur data science pour porter l'offre data science\\n\"\n",
      "                'offre publiée le 22-06-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction head of data management\\n'\n",
      "                'lead manager responsable\\n'\n",
      "                'technologies bigquery\\n'\n",
      "                'technologies data studio\\n'\n",
      "                'technologies google cloud plateform\\n'\n",
      "                'technologies machine learning\\n'\n",
      "                'technologies nlp\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies qlikview\\n'\n",
      "                'technologies tableau\\n'\n",
      "                'expérience 6 à 10 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 120k€\\n'\n",
      "                'max 140k€\\n'\n",
      "                'la startup : un acteur du conseil spécialisé dans le '\n",
      "                'marketing digital et la data\\n'\n",
      "                'une top équipe : grandes écoles et anciens de cabinets de '\n",
      "                'conseil\\n'\n",
      "                'une clientèle diversifiée auprès de différents acteurs : la '\n",
      "                'française des jeux, groupe bayard, kenzo, ovh,\\n'\n",
      "                'boardriders, vente-privée.com, …\\n'\n",
      "                'des locaux au coeur de paris\\n'\n",
      "                'un cabinet en pleine croissance, intégré à un grand groupe en '\n",
      "                '2018 (agence digitale présente dans 15 pays)\\n'\n",
      "                'une dimension entrepreneuriale forte (culture, autonomie sur '\n",
      "                'les missions, valeurs, petit effectif)\\n'\n",
      "                'un projet early stage où avoir de l’impact (10 à 30 '\n",
      "                'personnes)\\n'\n",
      "                'créé en 2015\\n'\n",
      "                'environnement technique : nlp, machine learning, bigquery, '\n",
      "                'google cloud platform, qlikview, tableau, data studio, sql, '\n",
      "                'python\\n'\n",
      "                'votre mission : piloter une equipe de 2 data scientist et '\n",
      "                'driver des projets data science\\n'\n",
      "                'en relation directe avec les associés, vous prenez en charge '\n",
      "                'le pôle data science et assurez son\\n'\n",
      "                'développement notamment l’encadrement des missions, le '\n",
      "                'développement des compétences rh, la gestion de charge, les '\n",
      "                'démarches commerciales, la communication, …\\n'\n",
      "                'vous pilotez (selon le niveau d’expertise requis) les '\n",
      "                'missions chez les clients relevant de la manipulation et '\n",
      "                'l’analyse avancée de données :\\n'\n",
      "                'recueil des besoins & définition des cas d’usage business\\n'\n",
      "                'architecture et mise en place des solutions techniques :\\n'\n",
      "                'data engineering : construction d’infrastructures de données '\n",
      "                'basées sur le cloud, flux de données entre différents outils '\n",
      "                'de l’écosystème data-marketing, …\\n'\n",
      "                'data science : algorithmie, analyse descriptive et '\n",
      "                'prédictive, machine learning, …\\n'\n",
      "                'data visualisation : construction de dashboards adaptés aux '\n",
      "                'enjeux opérationnels et managériaux\\n'\n",
      "                'vous gérez les appels d’offres / benchmarks de technologies\\n'\n",
      "                'vous êtes le responsable de l’évangélisation et la formation '\n",
      "                'aux enjeux data-marketing et data science\\n'\n",
      "                'encadrer et faire évoluer votre équipe de 3 personnes\\n'\n",
      "                'votre profil : directeur data science\\n'\n",
      "                'vous êtes diplômé d’une grande école de commerce, '\n",
      "                'd’ingénieurs ou équivalent, vous disposez :\\n'\n",
      "                'vous avez 7 années minimum d’expérience dans le conseil sur '\n",
      "                'des enjeux digitaux ou sur un poste lié au marketing '\n",
      "                'digital,\\n'\n",
      "                'vous avez été exposé à des sujets de traitements de données\\n'\n",
      "                'vous avez acquis une bonne compréhension des enjeux data et '\n",
      "                'avez une bonne vision des tendances du marché\\n'\n",
      "                'vous justifiez d’une solide expérience technique en matière '\n",
      "                'de traitement de données et d’encadrement de ce type de '\n",
      "                'projets\\n'\n",
      "                'vous êtes familier des outils google cloud platform et des '\n",
      "                'langages sql et python\\n'\n",
      "                'rigoureux, vous savez adopter une approche analytique '\n",
      "                'structurée et une posture conseil\\n'\n",
      "                'dans un contexte d’entreprise en croissance, vous avez pour '\n",
      "                'ambition d’être un élément clé du cabinet et souhaitez '\n",
      "                'assurer, en plus de votre rôle opérationnel, des fonctions de '\n",
      "                'management et de développement commercial\\n'\n",
      "                'modalités :\\n'\n",
      "                'package 120 à 140k€ (80k€ fixe, variable selon profil – à '\n",
      "                'discuter sur les objectifs)\\n'\n",
      "                'rtt : 10 jours\\n'\n",
      "                'jours de congés offerts ponctuellement\\n'\n",
      "                'petit déjeuners tous les lundis et panier de fruits\\n'\n",
      "                'carte lunchr\\n'\n",
      "                'mutuelle\\n'\n",
      "                'sélectionné par deborah peter\\n'\n",
      "                'spécialiste infra / devops / qa\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_6e9d52a296adec46',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=6e9d52a296adec46&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '120 000 € - 140 000 € par an',\n",
      " 'Skills': 'sql',\n",
      " 'Title': \"directeur data science pour porter l'offre data science\",\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab992'),\n",
      " 'index': 346,\n",
      " 'level_0': 346}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'offre publiée le 10-07-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 21 à 50\\n'\n",
      "                'technologies agile\\n'\n",
      "                'technologies git\\n'\n",
      "                'technologies machine learning\\n'\n",
      "                'technologies nlp\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies scikit learn\\n'\n",
      "                'technologies spark\\n'\n",
      "                'technologies tensorflow\\n'\n",
      "                'expérience 1 à 2 ans\\n'\n",
      "                'expérience 3 à 5 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 50k€\\n'\n",
      "                'max 65k€\\n'\n",
      "                '\\n'\n",
      "                'conseil en stratégie & management, spécialisé data\\n'\n",
      "                \"l'entreprise accompagne ses clients à valoriser leurs données \"\n",
      "                \"en menant des projets big data et d'intelligence \"\n",
      "                'artificielle. les consultants interviennent de bout en bout, '\n",
      "                \"de la conception de la stratégie à l'exploitation des \"\n",
      "                'plateformes technologiques.\\n'\n",
      "                \"rejoindre l'aventure c'est se spécialisér sur des \"\n",
      "                'problématiques de machine learning, deep learning et big '\n",
      "                'data.\\n'\n",
      "                'année de création : 2016\\n'\n",
      "                'effectif : 36 collaborateurs\\n'\n",
      "                'très bon positionnement : directions générales, marketing, '\n",
      "                'innovation ou data lab (pas de dsi)\\n'\n",
      "                'clients diversifiés : média, banques, industries, retail\\n'\n",
      "                'problématiques : spécialisé data, à un niveau conseil en '\n",
      "                'stratégie et management (vs agences)\\n'\n",
      "                'pur conseil : les missions sont vendues au forfait et vous '\n",
      "                'revenez au cabinet 1 à 2 jours par semaine\\n'\n",
      "                'missions courtes : 2/3 mois\\n'\n",
      "                'équipes : grandes écoles et du top30 des cabinets de conseil\\n'\n",
      "                'top formation : conférences payantes, formations internes… – '\n",
      "                'le bon endroit pour monter en compétence\\n'\n",
      "                'top locaux : en plein coeur de paris\\n'\n",
      "                'notre avis chez data recrutement, en tant que cabinet de '\n",
      "                'chasse :\\n'\n",
      "                'le type de cabinet de conseil avec des missions très '\n",
      "                'intéressantes (courtes, stratégiques, utiles) et une culture '\n",
      "                'd’entreprise startup.\\n'\n",
      "                'votre mission : data scientist – big data – ia\\n'\n",
      "                'en étroite collaboration avec le manager et le bureau de '\n",
      "                'paris, vous devrez :\\n'\n",
      "                'contribuer à la réalisation de projets technologiques en '\n",
      "                'intelligence artificielle (ia), r&d et/ou auprès de clients '\n",
      "                'grands comptes\\n'\n",
      "                'apporter des réponses concrètes à un besoin métier grâce à '\n",
      "                'l’ia : concevoir, développer, tester et industrialiser les '\n",
      "                'algorithmes et les solutions\\n'\n",
      "                'déployer des cas d’usages data variés, allant du marketing '\n",
      "                'prédictif à l’analyse d’image, en passant par le nlp\\n'\n",
      "                'encadrer et mentorer des data scientists juniors\\n'\n",
      "                'votre profil : data scientist confirmé(e)\\n'\n",
      "                'rencontrons-nous si :\\n'\n",
      "                \"vous êtes diplômé(e) d'une top école d’ingénieur avec une \"\n",
      "                'formation data (x, centralesupélec, mines, ensae, …) ou un '\n",
      "                'bac+5 orienté data\\n'\n",
      "                'vous avez idéalement une première expérience dans un cabinet '\n",
      "                'de conseil en stratégie et management\\n'\n",
      "                'vos 2 ans d’expérience minimum (hors stage) sur des outils de '\n",
      "                'gestion de la donnée font de vous un(e) expert(e) : r, '\n",
      "                'python, spark, hadoop, nosql databases (mongodb, cassandra, '\n",
      "                'hbase), tensorflow\\n'\n",
      "                'vous avez de bonnes connaissances en ia : machine learning, '\n",
      "                'deep learning, nlp, computer vision, transfer learning\\n'\n",
      "                'vous souhaitez participer à l’aventure d’un cabinet déjà très '\n",
      "                'reconnu et en forte croissance dans une culture startup\\n'\n",
      "                \"parler français/anglais couramment n'est pas un problème\\n\"\n",
      "                'modalités :\\n'\n",
      "                'package : 50/65k€ selon expérience\\n'\n",
      "                'processus de recrutement rapide :\\n'\n",
      "                'entretien téléphonique\\n'\n",
      "                \"test technique sur de l'algorithmique en python\\n\"\n",
      "                'rencontre avec le directeur technique\\n'\n",
      "                'sélectionné par thomas gourmelon\\n'\n",
      "                'spécialiste python, ruby, go & data scientist\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_b0d8a34fad9bf199',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=b0d8a34fad9bf199&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '50 000 € - 65 000 € par an',\n",
      " 'Skills': 'nosql',\n",
      " 'Title': 'data scientist confirmé(e)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab993'),\n",
      " 'index': 347,\n",
      " 'level_0': 347}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'offre publiée le 10-07-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 1 à 10\\n'\n",
      "                'teletravail a 100\\n'\n",
      "                'lead manager responsable a court terme\\n'\n",
      "                'technologies bert\\n'\n",
      "                'technologies nlp\\n'\n",
      "                'technologies tensorflow\\n'\n",
      "                'expérience 6 à 10 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 60k€\\n'\n",
      "                'max 100k€\\n'\n",
      "                '\\n'\n",
      "                'entreprise : la startup adtech disruptive dans la publicité '\n",
      "                'en ligne\\n'\n",
      "                '\\n'\n",
      "                'rgpd oblige, cette adtech prépare la solution de publicité en '\n",
      "                'ligne de l’après cookie : l’intelligence artificielle '\n",
      "                '(pretargeting sémantique) au service d’un ciblage qui ne '\n",
      "                'traque pas les utilisateurs.\\n'\n",
      "                'la première solution de ciblage publicitaire sans cookie\\n'\n",
      "                'use case disruptif sur le marché de la publicité en ligne\\n'\n",
      "                'background monstrueux du fondateur\\n'\n",
      "                'potentiel très important : le prochain criteo\\n'\n",
      "                'ouverture de poste suite à levée de fond + 500k\\n'\n",
      "                'locaux au coeur de paris\\n'\n",
      "                'stack technique du poste : python, tensorflow, nlp, deep '\n",
      "                'learning & transformers, …\\n'\n",
      "                'mon avis : un timing parfait pour un intrapreneur / data '\n",
      "                'scientist qui souhaite un projet cadré mais où beaucoup reste '\n",
      "                'à construire. une adtech du bon côté de l’histoire.\\n'\n",
      "                'votre mission : développer l’algorithme\\n'\n",
      "                'a partir d’une base/plateforme déjà existante, vous oeuvrez à '\n",
      "                'l’optimisation de l’algorithme pour optimiser le ciblage des '\n",
      "                'publicités en fonction du contexte (et non du cookie de '\n",
      "                'l’utilisateur)\\n'\n",
      "                \"optimiser un moteur nlp pour évaluer l'affinité d'une page \"\n",
      "                'web avec un produit ou une marque\\n'\n",
      "                \"avoir la responsabilité de vos modèles, de l'expérimentation \"\n",
      "                'à la mise en production\\n'\n",
      "                'intervenir sur un grand volume de données (un panel de 2 '\n",
      "                'millions de devices, 10 millions de pages analysées par '\n",
      "                'jour)\\n'\n",
      "                'encadrer plusieurs juniors à horizon de 1 an\\n'\n",
      "                'votre profil : data scientist senior nlp\\n'\n",
      "                'diplômé d’une grande école d’ingénieur ou phd : '\n",
      "                'polytechnique, centralesupelec, ens…\\n'\n",
      "                '3 à 10 ans d’expérience en data science\\n'\n",
      "                'expérience significative en nlp\\n'\n",
      "                'connaissance de l’inférence bayésienne ou excellent niveau en '\n",
      "                'mathématiques\\n'\n",
      "                'compréhension des enjeux business\\n'\n",
      "                'vous êtes autonome et force de proposition\\n'\n",
      "                'si précédente expérience dans l’adtech, c’est en plus !\\n'\n",
      "                'modalités :\\n'\n",
      "                'salaire : 60/100k€ selon profil\\n'\n",
      "                'paris hyper centre\\n'\n",
      "                'process de recrutement :\\n'\n",
      "                '2 à 3 entretiens avec le fondateur (rencontre, cas pratique)\\n'\n",
      "                'rencontre avec les business angels (selon profil)\\n'\n",
      "                '\\n'\n",
      "                'sélectionné par thomas gourmelon\\n'\n",
      "                'spécialiste python, ruby, go & data scientist\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_ff0f7d7afd4adcf4',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=ff0f7d7afd4adcf4&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '60 000 € - 100 000 € par an',\n",
      " 'Skills': 'nlp',\n",
      " 'Title': 'senior data scientist nlp pour réinventer l’après cookie dans la '\n",
      "          'adtech',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab995'),\n",
      " 'index': 349,\n",
      " 'level_0': 349}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'offre publiée le 10-07-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 21 à 50\\n'\n",
      "                'teletravail ponctuel\\n'\n",
      "                'technologies agile\\n'\n",
      "                'technologies aws\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies scala\\n'\n",
      "                'technologies spark\\n'\n",
      "                'expérience 3 à 5 ans\\n'\n",
      "                'expérience 6 à 10 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 55k€\\n'\n",
      "                'max 80k€\\n'\n",
      "                '\\n'\n",
      "                \"l'entreprise : start-up big data solution saas\\n\"\n",
      "                \"l'entreprise propose une plateforme web intégrant des \"\n",
      "                'analyses de quantification et qualification de flux pour ses '\n",
      "                \"clients. son champ d'action relève du big data.\\n\"\n",
      "                'quelques informations :\\n'\n",
      "                'année de création : 2016\\n'\n",
      "                '+200 clients grands comptes\\n'\n",
      "                'effectif total : 30 personnes\\n'\n",
      "                'effectif technique : 10 personnes\\n'\n",
      "                'volumétrie de données : 50 gigaoctets par jour\\n'\n",
      "                '1m€ de revenus récurrents\\n'\n",
      "                'activité essentiellement en france et développement récent en '\n",
      "                'europe\\n'\n",
      "                \"environnement technique de l'entreprise : python, jupyter, \"\n",
      "                'scala, spark, zeppelin, aws, tests unitaires et déploiement '\n",
      "                'continu, revues de code\\n'\n",
      "                'vos missions : structurer, rechercher, concevoir, développer, '\n",
      "                'mentorer\\n'\n",
      "                \"au sein de l'équipe r&d vous devrez :\\n\"\n",
      "                'structurer la démarche de r&d (documentation, méthodologie, '\n",
      "                'bonne pratique...)\\n'\n",
      "                'intervenir sur des problématiques de classification et '\n",
      "                'prédiction\\n'\n",
      "                \"mettre au point des algorithmes permettant d'agréger des \"\n",
      "                'données en statistiques\\n'\n",
      "                'mentorer les data scientist juniors\\n'\n",
      "                \"avoir une réflexion en termes de perspectives d'ouvertures de \"\n",
      "                'nouveaux algorithmes et use cases\\n'\n",
      "                \"établir l'état de l’art et l'étude scientifique\\n\"\n",
      "                'travailler avec les data engineer pour implémenter vos '\n",
      "                'travaux\\n'\n",
      "                'votre profil : data scientist senior\\n'\n",
      "                'rencontrons-nous si :\\n'\n",
      "                \"vous avez au moins 3 ans d'expérience en data science dans un \"\n",
      "                'contexte de r&d\\n'\n",
      "                \"vous êtes issu(e) d'une formation bac+5 ou phd en data \"\n",
      "                'science\\n'\n",
      "                'les mathématiques et statistiques sont vos domaines de '\n",
      "                'prédilection\\n'\n",
      "                \"l'implémentation d'algorithmes complexes dans le but de \"\n",
      "                'confronter une théorie à une réalité vous attire\\n'\n",
      "                \"c'est un plus si :\\n\"\n",
      "                'vous avez déjà travaillé sur des données de géolocalisation\\n'\n",
      "                'modalités :\\n'\n",
      "                'rémunération : 55/80k€\\n'\n",
      "                'remote ponctuel\\n'\n",
      "                'locaux en plein coeur de paris\\n'\n",
      "                'processus de recrutement :\\n'\n",
      "                'entretien téléphonique\\n'\n",
      "                'test technique sur place ou à distance selon disponibilités\\n'\n",
      "                \"entretien physique avec le cto et d'autres personnes de \"\n",
      "                \"l'équipe\\n\"\n",
      "                'rencontre des autres équipes\\n'\n",
      "                'sélectionné par thomas gourmelon\\n'\n",
      "                'spécialiste python, ruby, go & data scientist\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_0d61b3cf956c49a8',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=0d61b3cf956c49a8&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '55 000 € - 80 000 € par an',\n",
      " 'Skills': '',\n",
      " 'Title': 'data scientist senior',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab996'),\n",
      " 'index': 350,\n",
      " 'level_0': 350}\n",
      "{'Company': 'data recrutement',\n",
      " 'Description': 'offre publiée le 10-07-2020.\\n'\n",
      "                'paris\\n'\n",
      "                'fonction data scientist ml ia nlp dl\\n'\n",
      "                'taille entreprise de 51 à 200\\n'\n",
      "                'technologies python\\n'\n",
      "                'technologies tableau\\n'\n",
      "                'expérience jeune à dipl me\\n'\n",
      "                'expérience 1 à 2 ans\\n'\n",
      "                'expérience 3 à 5 ans\\n'\n",
      "                'statut cdi\\n'\n",
      "                'min 40k€\\n'\n",
      "                'max 50k€\\n'\n",
      "                'l’entreprise : une startup saas de data analyse de la '\n",
      "                'greentech\\n'\n",
      "                'l’entreprise a pour projet d’accélérer la transition '\n",
      "                'écologique. pour ce faire elle développe une solution saas de '\n",
      "                'data analytics visant à améliorer l’efficacité énergétique.\\n'\n",
      "                'date de création : 2014\\n'\n",
      "                'croissance : double son ca tous les 12 mois\\n'\n",
      "                'levée de fonds série a de 2,5m€ et série b de 8m€\\n'\n",
      "                'plus de 120 clients\\n'\n",
      "                'effectif total : 75 personnes\\n'\n",
      "                'effectif technique : plus de la moitié\\n'\n",
      "                'missions : sourcer de nouvelles données en open-data\\n'\n",
      "                'en collaboration directe avec les data scientist et au sein '\n",
      "                'de l’équipe r&d vous aurez à :\\n'\n",
      "                'identifier des données en open-data\\n'\n",
      "                'nettoyer et intégrer les données en vue de leur exploitation\\n'\n",
      "                'analyser les données pour répondre aux différents cas d’usage '\n",
      "                'croisés chez les clients\\n'\n",
      "                'restituer ces analyses (dataviz, tableau…)\\n'\n",
      "                'communiquer avec les autres équipes\\n'\n",
      "                'profil recherché : data miner avec une formation en data '\n",
      "                'science\\n'\n",
      "                'idéalement issu(e) d’une formation en data science\\n'\n",
      "                'vous êtes junior ou confirmé(e) l’entreprise à besoin de '\n",
      "                'vous\\n'\n",
      "                'vous avez déjà travaillé sur du data mining à partir de '\n",
      "                'source de données publiques\\n'\n",
      "                'python est votre langage de prédilection\\n'\n",
      "                'vous avez une expérience en data visualisation\\n'\n",
      "                'le fait d’être responsable d’une ouverture sur de nouveaux '\n",
      "                'horizons pour l’entreprise vous attire\\n'\n",
      "                'le domaine de la transition écologique vous intéresse\\n'\n",
      "                'pourquoi les rejoindre ?\\n'\n",
      "                'vous investir dans l’accélération de la transition '\n",
      "                'écologique\\n'\n",
      "                'rejoindre une startup à un moment clé de sa croissance\\n'\n",
      "                'relever des responsabilités techniques à la hauteur de votre '\n",
      "                'talent\\n'\n",
      "                'contribuer à un écosystème dynamique où les initiatives de '\n",
      "                'chacun ont leur place\\n'\n",
      "                'modalités :\\n'\n",
      "                'locaux : 10e arrondissement\\n'\n",
      "                'salaire : 40/50k€ selon profil et expériences\\n'\n",
      "                'pour en savoir plus : thomas.gourmelon@datarecrutement.fr\\n'\n",
      "                'merci d’envoyer au plus vite votre cv / votre profil linkedin '\n",
      "                'par e-mail avec comme objet « data miner greentech» à thomas '\n",
      "                'gourmelon (thomas.gourmelon@datarecrutement.fr), responsable '\n",
      "                'du pôle javascript & mobile au sein de data recrutement.\\n'\n",
      "                'sélectionné par thomas gourmelon\\n'\n",
      "                'spécialiste python, ruby, go & data scientist\\n'\n",
      "                'connaître le nom de l’entreprise',\n",
      " 'ID': 'p_b1fa9b504bcfe62d',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=b1fa9b504bcfe62d&fccid=10537848cbfc6a26&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '40 000 € - 50 000 € par an',\n",
      " 'Skills': '',\n",
      " 'Title': 'data miner',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab997'),\n",
      " 'index': 351,\n",
      " 'level_0': 351}\n",
      "{'Company': 'socio data management',\n",
      " 'Description': 'contexte\\n'\n",
      "                'depuis plus de 40 ans, socio data management est leader dans '\n",
      "                'le traitement et l’analyse de données, ainsi que dans les '\n",
      "                'solutions applicatives pour en optimiser l’exploitation et la '\n",
      "                'restitution.\\n'\n",
      "                'nos consultants experts accompagnent nos clients durant '\n",
      "                'toutes les étapes de leurs projets data : depuis le recueil '\n",
      "                'et l’intégration des données jusqu’à leur mise à disposition '\n",
      "                'sur des plateformes en ligne, nous mettons notre savoir-faire '\n",
      "                'au service de nos clients sur toute la chaîne de valeur de la '\n",
      "                'data.\\n'\n",
      "                'spécialistes des modélisations intelligentes, nous les aidons '\n",
      "                'à exploiter efficacement leurs données pour prendre des '\n",
      "                'décisions optimisées, tant sur le plan opérationnel que '\n",
      "                'stratégique.\\n'\n",
      "                'missions\\n'\n",
      "                'afin de renforcer nos équipes, nous recherchons un(e) '\n",
      "                'consultant(e) data scientist, pour intervenir chez l’un de '\n",
      "                'nos clients grands comptes.\\n'\n",
      "                'vous aurez pour mission :\\n'\n",
      "                'l’identification et la formalisation de business cases et des '\n",
      "                'problématiques des directions métiers ;\\n'\n",
      "                'l’exploration des données internes et externes ;\\n'\n",
      "                'la proposition de solutions adaptées ;\\n'\n",
      "                'la réalisation des projets big data (ingestion de sources, '\n",
      "                'traitements, tests, recettes, déploiements) ;\\n'\n",
      "                'le crunching, l’analyse et l’exploitation de données (crm, '\n",
      "                'produits, digitales, logistique, yield, open data…) ;\\n'\n",
      "                'l’optimisations et l’industrialisations des modèles de '\n",
      "                'machine learning et d’intelligence artificielle.\\n'\n",
      "                'profil recherché\\n'\n",
      "                'vous êtes diplômé(e) d’un bac + 5 dans un domaine tel que les '\n",
      "                'statistiques, l’informatique, l’ingénierie, les '\n",
      "                'mathématiques, et vous justifiez idéalement d’une première '\n",
      "                'expérience en machine learning/big data/analytics.\\n'\n",
      "                'une expertise en mathématiques appliquées (statistiques, '\n",
      "                'optimisation, machine learning, nlp) est indispensable.\\n'\n",
      "                'vous maîtrisez la programmation informatique : python '\n",
      "                '(pandas, numpy, scikit-learn), r, c++, scala, spark… et vous '\n",
      "                'avez de solides connaissances en algorithmie et gestion des '\n",
      "                'bases de données (sql, nosql, mapreduce, hadoop…).\\n'\n",
      "                'doté d’une grande qualité d’écoute et d’analyse, vous aimez '\n",
      "                'travailler en équipe. vous êtes curieux de nature et '\n",
      "                'passionné par la data, avec le souhait de mettre vos '\n",
      "                'compétences au service des clients.\\n'\n",
      "                'nous rejoindre\\n'\n",
      "                'rejoindre l’équipe socio data management c’est :\\n'\n",
      "                'un engagement de proximité : entreprise à taille humaine, '\n",
      "                'nous restons proches de nos collaborateurs afin de les '\n",
      "                'accompagner de façon pertinente dans leurs carrières.\\n'\n",
      "                'une garantie de diversité : nous intervenons sur des projets '\n",
      "                'divers, enrichissants, innovants et à forte valeur ajoutée '\n",
      "                'pour nos clients dans différents secteurs d’activités.\\n'\n",
      "                'une promesse d’innovation : en tant qu’expert data, nous '\n",
      "                'faisons partie du data lab, un véritable pôle r&d qui a pour '\n",
      "                'vocation de faire émerger des initiatives innovantes.\\n'\n",
      "                'un gage d’intégration : faisant partie intégrante d’un '\n",
      "                'groupe, nos collaborateurs ont la possibilité de créer et de '\n",
      "                'tisser du lien, tout en développant leurs connaissances sur '\n",
      "                'des sujets transverses (cybersécurité, gestion des risques, '\n",
      "                'it…).\\n'\n",
      "                'bénéficier de nos avantages : accès à notre plateforme ce, '\n",
      "                'attribution de chèques-cadeaux, tickets-restaurants, prime '\n",
      "                'vacances…',\n",
      " 'ID': 'p_9f851d7627cb8423',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=9f851d7627cb8423&fccid=1df4655865e4f1e9&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'python',\n",
      " 'Title': 'consultant(e) data scientist',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab9a4'),\n",
      " 'index': 364,\n",
      " 'level_0': 364}\n",
      "{'Company': 'cybelangel',\n",
      " 'Description': 'nous traitons des milliards de documents chaque jour pour en '\n",
      "                'extraire simplement les fuites de données pertinentes '\n",
      "                'concernant nos clients !\\n'\n",
      "                'introduire de l’intelligence aux divers niveaux de notre '\n",
      "                'pipeline de traitement est donc un enjeu crucial pour '\n",
      "                'cybelangel. notre équipe data science a pour mission de '\n",
      "                'rendre nos algorithmes de filtrage les plus intelligents '\n",
      "                'possible, en vue d’optimiser et de faciliter le traitement '\n",
      "                'des incidents de sécurité délivrés à nos clients.\\n'\n",
      "                '\\n'\n",
      "                '**missions**\\n'\n",
      "                'l’équipe data science conçoit, implémente, intègre et '\n",
      "                'optimise des modèles de machine learning pour automatiser '\n",
      "                'intelligemment le traitement massif de documents.\\n'\n",
      "                'au sein de l’équipe, tes missions en tant que senior data '\n",
      "                'scientist seront les suivantes:\\n'\n",
      "                \"récupération des data, exploration, état de l'art, \"\n",
      "                'documentation, benchmarking, développement, déploiement. pour '\n",
      "                'quoi faire ? catégoriser, scorer, extraire des informations '\n",
      "                'sensibles (textes et images) !\\n'\n",
      "                'développer et optimiser les algorithmes avec le reste de '\n",
      "                'l’équipe engineering (software developers, full stack '\n",
      "                'developers, devops etc…) pour pouvoir analyser en temps réel '\n",
      "                'des milliards de documents par jour !\\n'\n",
      "                'collaborer avec nos cyber-risk analysts et product managers '\n",
      "                'pour définir et maintenir des objectifs de précision et '\n",
      "                'performance des modèles;\\n'\n",
      "                'encadrer techniquement et valider les bonnes pratiques des '\n",
      "                'data scientists plus junior dans l’exécution des projets;\\n'\n",
      "                'concevoir, planifier et prioriser les projets en cours;\\n'\n",
      "                'collaborer avec les autres équipes (engineering, produit et '\n",
      "                'cyber analystes);\\n'\n",
      "                'promouvoir les bonnes pratique dans notre équipe;\\n'\n",
      "                'réaliser des veilles technologiques et être force de '\n",
      "                'proposition sur toutes les nouvelles technologies.\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'les + du job:\\n'\n",
      "                'faire partie d’une équipe soudée et passionnée de data '\n",
      "                'scientists et data engineers (organisation de cybelkaggle, '\n",
      "                'participation à des conférences, meetup et formations).\\n'\n",
      "                'les projets labs : chez cybelangel, chaque ingénieur alloue '\n",
      "                '20% de son temps au projet personnel de son choix (formations '\n",
      "                'sur les nouvelles technos, tester des idées innovantes etc…)\\n'\n",
      "                'tu es quotidiennement en lien direct avec les experts '\n",
      "                \"analystes en cybersécurité ce qui te permet d'avoir un impact \"\n",
      "                'global et stratégique.\\n'\n",
      "                'profiter de tous les avantages d’un environnement de travail '\n",
      "                'fun et agréable au quotidien: cours de yoga, petit-déjeuners, '\n",
      "                \"bootcamp, afterworks, meetups et bien d'autres !\\n\"\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'stack techno\\n'\n",
      "                'dbs: elasticsearch, mongo, redis, bigquery\\n'\n",
      "                'infra: gcp, docker, kubernetes, datadog, gitlab ci, rabbitmq\\n'\n",
      "                'frontend: vuejs/vuex, scss, bulma\\n'\n",
      "                'backend: python\\n'\n",
      "                'requirements\\n'\n",
      "                'compétences requises\\n'\n",
      "                'au minimum 3 ans d’expérience en tant que data scientist au '\n",
      "                \"sein d'un environnement ml\\n\"\n",
      "                'passionné par le machine learning\\n'\n",
      "                \"tu est doté d'un esprit d'équipe\\n\"\n",
      "                'bac +5 ou plus en statistique, probabilité, mathématique ou '\n",
      "                'machine learning\\n'\n",
      "                'maitrise de python\\n'\n",
      "                'excellente communication pour pouvoir comprendre, synthétiser '\n",
      "                'et expliquer des problèmes complexes de manière simple avec '\n",
      "                'les équipes product, engineering et analyst.\\n'\n",
      "                'autonomie sur la conception et l’implémentation de nouvelles '\n",
      "                'solutions, force de proposition et créativité\\n'\n",
      "                'une expériences réussie en gestion et développement de '\n",
      "                'projets data science\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'compétences appréciées\\n'\n",
      "                'compétence en data/software engineering\\n'\n",
      "                'bon niveau de compréhension en nlp\\n'\n",
      "                'a l’aise en data viz’\\n'\n",
      "                'traitement de datasets volumineux\\n'\n",
      "                'expérience avec des technologies big data : elasticsearch, '\n",
      "                'cassandra, mongodb, hadoop, rabbitmq\\n'\n",
      "                'expérience avec tensorflow/pytorch\\n'\n",
      "                'expérience dans un environnement agile, idéalement scrum\\n'\n",
      "                'benefits\\n'\n",
      "                'localisation: paris\\n'\n",
      "                'contrat: cdi à temps plein\\n'\n",
      "                'rémunération: selon profil et expérience',\n",
      " 'ID': 'p_c04301d0ac0d39c0',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=c04301d0ac0d39c0&fccid=31a8882d159403e5&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': '',\n",
      " 'Title': 'senior data scientist h/f',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab9af'),\n",
      " 'index': 375,\n",
      " 'level_0': 375}\n",
      "{'Company': 'aquila consulting',\n",
      " 'Description': 'notre mission\\n'\n",
      "                'en tant que spécialiste reconnu, aquila data enabler '\n",
      "                'accompagne et conseille ses clients sur la data science et\\n'\n",
      "                'l’intégration big data, principalement au sein des labs r&d.\\n'\n",
      "                'notre positionnement est celui de la recherche '\n",
      "                'opérationnelle. aquila data enabler est une structure qui '\n",
      "                'répond avec\\n'\n",
      "                'réactivité, transparence et proximité aux besoins de ses '\n",
      "                'clients en les aidant à faire les bons choix, et à les mettre '\n",
      "                'en oeuvre\\n'\n",
      "                'avec efficacité.\\n'\n",
      "                'poste propose\\n'\n",
      "                'pour un client grand compte basé sur paris, vous travaillerez '\n",
      "                'au sein de leur lab sur plusieurs projets, en tant que data\\n'\n",
      "                'scientist (f/h) spécialisé nlp / text mining.\\n'\n",
      "                '\\n'\n",
      "                'vos missions seront :\\n'\n",
      "                '\\n'\n",
      "                'ü accompagnement du client pour l’émergence des besoins '\n",
      "                'centrés sur la donnée\\n'\n",
      "                'ü etude de la problématique posée, diagnostic de la situation '\n",
      "                'et des données disponibles, préparation des données\\n'\n",
      "                'ü proposition de méthodes de modélisation des problèmes '\n",
      "                'opérationnels, conception d’algorithmes de classification,\\n'\n",
      "                'modélisation, prévision et optimisation\\n'\n",
      "                'ü validation des modèles, mise en place d’indicateurs '\n",
      "                'pertinents, étude des résultats, recommandations.\\n'\n",
      "                'ü conception d’outils d’analyse et de data-visualisation\\n'\n",
      "                '\\n'\n",
      "                'vous aborderez des questions stratégiques et opérationnelles '\n",
      "                'complexes, auxquels vous pouvez apporter des réponses grâce\\n'\n",
      "                'à votre bagage technique (data mining et visualisation de '\n",
      "                \"données techniques, l'analyse graphique, l'analyse \"\n",
      "                'statistique,\\n'\n",
      "                'le machine learning / deep learning, etc).\\n'\n",
      "                '\\n'\n",
      "                'voici quelques exemples de problématiques nlp pouvant être '\n",
      "                'rencontrées :\\n'\n",
      "                '\\n'\n",
      "                'chatbot\\n'\n",
      "                'reconnaissance automatique de la parole (chaînes télévisées, '\n",
      "                'appels téléphoniques, etc)\\n'\n",
      "                'lecture automatique de document (documents d’identité, '\n",
      "                'contrats, tableaux, etc : ocr)\\n'\n",
      "                'analyse de sentiments clients (à la suite d’un questionnaire, '\n",
      "                'réseaux sociaux, etc)\\n'\n",
      "                'analyse de données exogènes (journaux, site internet, etc)\\n'\n",
      "                'analyse automatique de rapports humains\\n'\n",
      "                '\\n'\n",
      "                'vous serez également responsable du pilotage de ses projets '\n",
      "                '(définition de périmètre, planning et respect des délais,\\n'\n",
      "                'coordination avec les autres départements).\\n'\n",
      "                '\\n'\n",
      "                'de même, vous pourrez avoir des missions commerciales '\n",
      "                '(réunions et présentations clients, workshop, etc) et des '\n",
      "                'missions de\\n'\n",
      "                'veille (rédaction d’articles sur les projets aquila en cours, '\n",
      "                'etc).\\n'\n",
      "                '\\n'\n",
      "                'vos qualifications\\n'\n",
      "                'ingénieur data scientist diplômé bac +5 / doctorat, vous avez '\n",
      "                'acquérit une spécialisation nlp / text mining / '\n",
      "                'reconnaissance\\n'\n",
      "                'automatique de la parole de par vos études (thèse) ou via vos '\n",
      "                'premières expériences professionnelles.\\n'\n",
      "                '\\n'\n",
      "                'les algorithmes sont vos meilleurs amis et le réseau de '\n",
      "                'neurones n’a plus de secret pour vous !\\n'\n",
      "                '\\n'\n",
      "                'vous êtes passionné par la recherche, mais en même temps vous '\n",
      "                'êtes attiré par le fait de travailler sur de vraies\\n'\n",
      "                'problématiques opérationnelles au sein d’une grande '\n",
      "                'entreprise.\\n'\n",
      "                '.\\n'\n",
      "                'idéalement, comme outils, vous maîtrisez python et r.\\n'\n",
      "                '\\n'\n",
      "                'enfin, vous avez la pêche, le smile attitude, assez pour '\n",
      "                'prétendre de faire partie de l’aquila team !\\n'\n",
      "                '\\n'\n",
      "                'si vous vous reconnaissez dans cette description, n’hésitez '\n",
      "                'pas à nous envoyer votre candidature, nous serons ravis de '\n",
      "                'faire\\n'\n",
      "                'connaissance autour d’un café !\\n'\n",
      "                'envie de rejoindre notre equipe ?\\n'\n",
      "                'merci de nous envoyer votre cv et lettre de motivation à '\n",
      "                'jobs@aquiladata.fr\\n'\n",
      "                'pour un traitement interne plus rapide, veuillez nommer vos '\n",
      "                \"documents comme suit : prénom nom_cv ou cl. n'hésitez pas\\n\"\n",
      "                'à ajouter tout document divers pouvant supporter votre '\n",
      "                'demande. nous veillerons à examiner votre demande et à vous\\n'\n",
      "                'répondre dans les 48h.',\n",
      " 'ID': 'p_de3d6a38994d3902',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=de3d6a38994d3902&fccid=7f78fab353adfeb3&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': 'pythonnlp',\n",
      " 'Title': 'data scientist nlp',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab9c0'),\n",
      " 'index': 392,\n",
      " 'level_0': 392}\n",
      "{'Company': 'konekt',\n",
      " 'Description': \"description de l'emploi\\n\"\n",
      "                'notre client, pme dynamique de 180 collaborateurs et leader '\n",
      "                'sur son marché recherche un lead data scientist.\\n'\n",
      "                'job description\\n'\n",
      "                'faire de de notre une véritable plateforme de recommandation '\n",
      "                'de contenus personnalisés pour nos étudiants, prenant en '\n",
      "                'compte l’ensemble des étapes du cycle de vie étudiant\\n'\n",
      "                'mettre en place des modèles de prévision de l’activité '\n",
      "                'étudiante sur la plateforme (inscriptions, churn, traffic, '\n",
      "                'candidatures, etc.) pour alimenter la vision stratégique des '\n",
      "                'équipes métier\\n'\n",
      "                'accompagner et former l’équipe de ds, notamment dans le cadre '\n",
      "                'du passage à l’environnement spark\\n'\n",
      "                'veiller aux bonnes pratiques en termes de qualité du code, de '\n",
      "                'performance et de scalabilité des algorithmes au sein de '\n",
      "                'l’équipe de ds\\n'\n",
      "                'assurer la coordination avec l’équipe de data ingénieurs '\n",
      "                '(mise en production) et de data analysts (kpis de suivi et de '\n",
      "                'd’évaluation d’impact)\\n'\n",
      "                'en trio avec le head of r&d et le head of data, contribuer à '\n",
      "                'l’émergence de nouveaux cas d’usage innovants en co-animant '\n",
      "                'une démarche open innovation\\n'\n",
      "                'contribuer à la construction de la roadmap ia de jobteaser\\n'\n",
      "                'contribuer au recrutement\\n'\n",
      "                'effectuer une veille scientifique active autour des sujets '\n",
      "                'ia\\n'\n",
      "                'qualifications\\n'\n",
      "                '3 ans minimum dans l’univers data science / ia\\n'\n",
      "                '\\n'\n",
      "                'compétences techniques\\n'\n",
      "                'connaissance approfondie des techniques de machine learning / '\n",
      "                'deep learning: régression, classification, clustering, '\n",
      "                'analyse de séries temporelles, modèles probabilistes, '\n",
      "                'optimisation\\n'\n",
      "                'une ou plusieurs expériences sur des systèmes de '\n",
      "                'recommandation ainsi qu’en traitement naturel du langage '\n",
      "                '(nlp) seraient un grand plus\\n'\n",
      "                'langages:\\n'\n",
      "                'connaissance approfondie de python, et en particulier des '\n",
      "                'librairies standard (pandas, scikit-learn, matplotlib, …), '\n",
      "                'ainsi qu’une librairie de deep learning (tensorflow, keras, '\n",
      "                'theano, …)\\n'\n",
      "                'sql, nosql\\n'\n",
      "                'une première expérience avec des plateformes cloud (aws, gcp, '\n",
      "                'digital ocean, …) ainsi qu’avec des environnements distribués '\n",
      "                '/ big data (spark, hadoop, …) est souhaitée\\n'\n",
      "                'une ou plusieurs expériences de mise en production '\n",
      "                'd’algorithmes de machine learning est également souhaitée\\n'\n",
      "                '\\n'\n",
      "                'autres compétences attendues\\n'\n",
      "                'gestion de projet\\n'\n",
      "                'leadership technique, pédagogie\\n'\n",
      "                'capacité à défendre la roadmap et les choix techniques\\n'\n",
      "                'additional information\\n'\n",
      "                'mise en avant de la culture tech :\\n'\n",
      "                'meetup internes\\n'\n",
      "                'accès à plusieurs conférences dans l’année\\n'\n",
      "                'accès à des plateformes e-learning et e-books\\n'\n",
      "                'après-midi de technical sharing & learning\\n'\n",
      "                'hackathon interne\\n'\n",
      "                'day out pour avancer des sides projects\\n'\n",
      "                'passion pour les best practices\\n'\n",
      "                'proche des équipes métier\\n'\n",
      "                'impliqués tant sur la technique que sur le produit\\n'\n",
      "                'les plus :\\n'\n",
      "                'labels “happy at work” et “great place to work”\\n'\n",
      "                'bureaux neufs en plein centre de paris\\n'\n",
      "                'télétravail autorisé\\n'\n",
      "                'espace permettant d’accueillir et d’organiser des meetups',\n",
      " 'ID': 'p_b62169f0a13047fc',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=b62169f0a13047fc&fccid=935c7a0afc5691c7&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': '70 000 € - 80 000 € par an',\n",
      " 'Skills': '',\n",
      " 'Title': 'lead data scientist',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab9cc'),\n",
      " 'index': 404,\n",
      " 'level_0': 404}\n",
      "{'Company': \"artur'in\",\n",
      " 'Description': 'tu rejoindras l’équipe ai, dont la mission est de mettre en '\n",
      "                'application les dernières avancées dans le domaine de '\n",
      "                'l’intelligence artificielle afin que artur — le community '\n",
      "                'manager virtuel — continue de se développer\\n'\n",
      "                'des applications (apis) sont déjà en production et doivent '\n",
      "                'être continuellement amliorées et complétées\\n'\n",
      "                'elles font notamment appel à du deep learning, du language '\n",
      "                'modeling et du transfer learning\\n'\n",
      "                'les pistes de recherche seront certainement dans les domaines '\n",
      "                'suivants : meta learning, computer vision et natural language '\n",
      "                'generation\\n'\n",
      "                'au quotidien, selon la place que tu prendras, tu devras\\n'\n",
      "                'mener des expériences avec des données et des modèles\\n'\n",
      "                'récolter et traîter des données\\n'\n",
      "                'développer de nouveaux modèles\\n'\n",
      "                'avoir des idées créatives pour adapter des solutions '\n",
      "                'académiques à des cas pratiques\\n'\n",
      "                'lire des papiers scientifiques\\n'\n",
      "                'faire évoluer / mettre en production des systèmes d’ai\\n'\n",
      "                'collaborer avec d’autres équipes\\n'\n",
      "                'continuer à te former\\n'\n",
      "                'profil recherché\\n'\n",
      "                'études\\n'\n",
      "                'niveau minimum : ingénieur (grandes écoles et/ou master 2 '\n",
      "                'et/ou phds)\\n'\n",
      "                'spécialité : statistiques / machine learning / data science\\n'\n",
      "                'expérience\\n'\n",
      "                '1 an dans une entreprise sur un poste alliant machine '\n",
      "                'learning et développement\\n'\n",
      "                'projet(s) de deep learning mené(s) en autonomie, de '\n",
      "                'l’idéation à la mise en production\\n'\n",
      "                'compétences fondamentales\\n'\n",
      "                'compréhension théorique avancée du machine learning\\n'\n",
      "                'maîtrise d’un framework de deep learning\\n'\n",
      "                'atouts\\n'\n",
      "                'expérience en nlp\\n'\n",
      "                'qualités de développeur\\n'\n",
      "                'qualités humaines\\n'\n",
      "                'confiance / autonomie\\n'\n",
      "                'intuition / créativité\\n'\n",
      "                'qualité de la communication\\n'\n",
      "                'honnêteté intellectuelle',\n",
      " 'ID': 'p_10c9ddc7e72d4041',\n",
      " 'Links': 'https://www.indeed.fr/rc/clk?jk=10c9ddc7e72d4041&fccid=1364a1e3e5795850&vjs=3',\n",
      " 'Location': 'paris (75)',\n",
      " 'Salary': 'none',\n",
      " 'Skills': '',\n",
      " 'Title': 'data science / machine learning engineer h/f (cdi)',\n",
      " '_id': ObjectId('5f5a3c7947aa23246ebab9d5'),\n",
      " 'index': 413,\n",
      " 'level_0': 413}\n"
     ]
    }
   ],
   "source": [
    "# https://www.it-swarm.dev/fr/regex/comment-utiliser-loperateur-not-dans-mongodb/1042778394/\n",
    "# matching pattern without regex :   https://www.guru99.com/regular-expressions-mongodb.html\n",
    "# https://kb.objectrocket.com/mongo-db/how-to-query-mongodb-documents-with-regex-in-python-362\n",
    "myquery = {\n",
    "    \"Location\" : { \"$regex\": \"paris\" },\n",
    "    \"Description\" : { \"$regex\": \"nlp\" }\n",
    "}\n",
    "    \n",
    "mydoc2 = mycol.find(myquery)\n",
    "for x in mydoc2:\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "if no direction is specified, key_or_list must be an instance of list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-db7c5df9c4f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforEach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"printjson\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\time_series\\venv\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36msort\u001b[1;34m(self, key_or_list, direction)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \"\"\"\n\u001b[0;32m    761\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__check_okay_to_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__ordering\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\time_series\\venv\\lib\\site-packages\\pymongo\\helpers.py\u001b[0m in \u001b[0;36m_index_list\u001b[1;34m(key_or_list, direction)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mASCENDING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             raise TypeError(\"if no direction is specified, \"\n\u001b[0m\u001b[0;32m     75\u001b[0m                             \"key_or_list must be an instance of list\")\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkey_or_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: if no direction is specified, key_or_list must be an instance of list"
     ]
    }
   ],
   "source": [
    "db.Indeed.find().sort({'ID':-1}).limit(2).forEach(\"printjson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
